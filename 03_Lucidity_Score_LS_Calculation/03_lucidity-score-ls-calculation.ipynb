{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Lucidity Score (LS) Calculation\nimport pandas as pd\nimport numpy as np\n\ndef calculate_lucidity_score():\n    \"\"\"\n    Calculate Lucidity Score based on actual evaluation data\n    \"\"\"\n    \n    # Average data across your multiple CSV runs\n    model_data = {\n        'Model': ['deepseek-llm', 'mistral:7b', 'llama3:8b', 'gemma:7b', 'qwen2.5:3b'],\n        'TruthfulQA': [53.3, 53.3, 56.0, 50.7, 52.7],\n        'HHEMRate': [4.0, 5.7, 6.5, 2.5, 5.0],  # Your actual HHEM scores\n        'Medical': [20.7, 28.3, 30.5, 24.8, 34.9],\n        'Legal': [17.2, 29.2, 28.5, 13.2, 28.2], \n        'Scientific': [15.0, 19.3, 16.3, 18.4, 17.7],\n        'Lucidity': [2.6, 2.0, 0.1, 3.3, 0.0]  # Average from your CSV data\n    }\n    \n    df = pd.DataFrame(model_data)\n    \n    # Calculate components for LS formula\n    # 1. TruthfulQA (already 0-100 scale)\n    df['TruthfulQA_component'] = df['TruthfulQA']\n    \n    # 2. HHEM normalized (higher HHEM = better, normalize to 0-100)\n    max_hhem = df['HHEMRate'].max()\n    df['HHEM_normalized'] = (df['HHEMRate'] / max_hhem) * 100\n    \n    # 3. Domain average (Medical + Legal + Scientific) / 3\n    df['Domain_avg'] = (df['Medical'] + df['Legal'] + df['Scientific']) / 3\n    \n    # 4. Lucidity penalty (100 - lucidity score, so higher lucidity = lower penalty)\n    df['Lucidity_penalty'] = 100 - df['Lucidity']\n    \n    # Calculate Lucidity Score (LS)\n    # LS = 0.25*TruthfulQA + 0.20*HHEM_norm + 0.35*Domain_avg + 0.20*Lucidity_penalty\n    df['LS'] = (0.25 * df['TruthfulQA_component'] + \n                 0.20 * df['HHEM_normalized'] + \n                 0.35 * df['Domain_avg'] + \n                 0.20 * df['Lucidity_penalty'])\n    \n    # Rank models by LS (higher = better)\n    df['LS_Rank'] = df['LS'].rank(ascending=False, method='min')\n    \n    # Display results\n    print(\"=== Lucidity Score (LS) Results ===\\n\")\n    \n    # Show component breakdown\n    components_df = df[['Model', 'TruthfulQA_component', 'HHEM_normalized', \n                       'Domain_avg', 'Lucidity_penalty', 'LS', 'LS_Rank']]\n    \n    print(\"Component Breakdown:\")\n    for _, row in components_df.iterrows():\n        print(f\"\\n{row['Model']}:\")\n        print(f\"  TruthfulQA: {row['TruthfulQA_component']:.1f}\")\n        print(f\"  HHEM (normalized): {row['HHEM_normalized']:.1f}\")  \n        print(f\"  Domain Average: {row['Domain_avg']:.1f}\")\n        print(f\"  Lucidity Penalty: {row['Lucidity_penalty']:.1f}\")\n        print(f\"  LS: {row['LS']:.1f} (Rank: {int(row['LS_Rank'])})\")\n    \n    print(f\"\\n{'='*50}\")\n    print(\"Final LS Rankings:\")\n    print(f\"{'='*50}\")\n    \n    ranked_df = components_df.sort_values('LS_Rank')\n    for i, (_, row) in enumerate(ranked_df.iterrows()):\n        print(f\"{int(row['LS_Rank'])}. {row['Model']}: {row['LS']:.1f}\")\n    \n    return df\n\n# Run LS calculation\nls_results = calculate_lucidity_score()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-13T18:49:36.580194Z","iopub.execute_input":"2025-09-13T18:49:36.580469Z","iopub.status.idle":"2025-09-13T18:49:37.150690Z","shell.execute_reply.started":"2025-09-13T18:49:36.580440Z","shell.execute_reply":"2025-09-13T18:49:37.149614Z"}},"outputs":[{"name":"stdout","text":"=== Lucidity Score (CRS) Results ===\n\nComponent Breakdown:\n\ndeepseek-llm:\n  TruthfulQA: 53.3\n  HHEM (normalized): 61.5\n  Domain Average: 17.6\n  Lucidity Penalty: 97.4\n  CRS: 51.3 (Rank: 4)\n\nmistral:7b:\n  TruthfulQA: 53.3\n  HHEM (normalized): 87.7\n  Domain Average: 25.6\n  Lucidity Penalty: 98.0\n  CRS: 59.4 (Rank: 2)\n\nllama3:8b:\n  TruthfulQA: 56.0\n  HHEM (normalized): 100.0\n  Domain Average: 25.1\n  Lucidity Penalty: 99.9\n  CRS: 62.8 (Rank: 1)\n\ngemma:7b:\n  TruthfulQA: 50.7\n  HHEM (normalized): 38.5\n  Domain Average: 18.8\n  Lucidity Penalty: 96.7\n  CRS: 46.3 (Rank: 5)\n\nqwen2.5:3b:\n  TruthfulQA: 52.7\n  HHEM (normalized): 76.9\n  Domain Average: 26.9\n  Lucidity Penalty: 100.0\n  CRS: 58.0 (Rank: 3)\n\n==================================================\nFinal LS Rankings:\n==================================================\n1. llama3:8b: 62.8\n2. mistral:7b: 59.4\n3. qwen2.5:3b: 58.0\n4. deepseek-llm: 51.3\n5. gemma:7b: 46.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Lucidity Score (LS) Calculation\nimport pandas as pd\nimport numpy as np\n\ndef calculate_lucidity_score():\n    \"\"\"\n    Calculate Lucidity Score based on actual evaluation data\n    \"\"\"\n    \n    # Average data across your multiple CSV runs\n    model_data = {\n        'Model': ['deepseek-llm', 'mistral:7b', 'llama3:8b', 'gemma:7b', 'qwen2.5:3b'],\n        'TruthfulQA': [52.7, 53.3, 56.0, 50.0, 51.3],\n        'HHEMRate': [5.0, 5.2, 7.0, 1.9, 4.3],  # Your actual HHEM scores\n        'Medical': [19.2, 32.8, 26.4, 21.9, 32.1],\n        'Legal': [21.3, 27.1, 26.4, 11.2, 31.6], \n        'Scientific': [14.4, 18.0, 17.1, 18.4, 18.9],\n        'Lucidity': [2.9, 1.8, 0.0, 2.7, 0.0]  # Average from your CSV data\n    }\n    \n    df = pd.DataFrame(model_data)\n    \n    # Calculate components for LS formula\n    # 1. TruthfulQA (already 0-100 scale)\n    df['TruthfulQA_component'] = df['TruthfulQA']\n    \n    # 2. HHEM normalized (higher HHEM = better, normalize to 0-100)\n    max_hhem = df['HHEMRate'].max()\n    df['HHEM_normalized'] = (df['HHEMRate'] / max_hhem) * 100\n    \n    # 3. Domain average (Medical + Legal + Scientific) / 3\n    df['Domain_avg'] = (df['Medical'] + df['Legal'] + df['Scientific']) / 3\n    \n    # 4. Lucidity penalty (100 - lucidity score, so higher lucidity = lower penalty)\n    df['Lucidity_penalty'] = 100 - df['Lucidity']\n    \n    # Calculate Lucidity Score (LS)\n    # LS = 0.25*TruthfulQA + 0.20*HHEM_norm + 0.35*Domain_avg + 0.20*Lucidity_penalty\n    df['LS'] = (0.25 * df['TruthfulQA_component'] + \n                 0.20 * df['HHEM_normalized'] + \n                 0.35 * df['Domain_avg'] + \n                 0.20 * df['Lucidity_penalty'])\n    \n    # Rank models by LS (higher = better)\n    df['LS_Rank'] = df['LS'].rank(ascending=False, method='min')\n    \n    # Display results\n    print(\"=== Lucidity Score (LS) Results ===\\n\")\n    \n    # Show component breakdown\n    components_df = df[['Model', 'TruthfulQA_component', 'HHEM_normalized', \n                       'Domain_avg', 'Lucidity_penalty', 'LS', 'LS_Rank']]\n    \n    print(\"Component Breakdown:\")\n    for _, row in components_df.iterrows():\n        print(f\"\\n{row['Model']}:\")\n        print(f\"  TruthfulQA: {row['TruthfulQA_component']:.1f}\")\n        print(f\"  HHEM (normalized): {row['HHEM_normalized']:.1f}\")  \n        print(f\"  Domain Average: {row['Domain_avg']:.1f}\")\n        print(f\"  Lucidity Penalty: {row['Lucidity_penalty']:.1f}\")\n        print(f\"  LS: {row['LS']:.1f} (Rank: {int(row['LS_Rank'])})\")\n    \n    print(f\"\\n{'='*50}\")\n    print(\"Final LS Rankings:\")\n    print(f\"{'='*50}\")\n    \n    ranked_df = components_df.sort_values('LS_Rank')\n    for i, (_, row) in enumerate(ranked_df.iterrows()):\n        print(f\"{int(row['LS_Rank'])}. {row['Model']}: {row['LS']:.1f}\")\n    \n    return df\n\n# Run LS calculation\nls_results = calculate_lucidity_score()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T19:31:32.635593Z","iopub.execute_input":"2025-09-13T19:31:32.635992Z","iopub.status.idle":"2025-09-13T19:31:32.658930Z","shell.execute_reply.started":"2025-09-13T19:31:32.635964Z","shell.execute_reply":"2025-09-13T19:31:32.657409Z"}},"outputs":[{"name":"stdout","text":"=== Lucidity Score (LS) Results ===\n\nComponent Breakdown:\n\ndeepseek-llm:\n  TruthfulQA: 52.7\n  HHEM (normalized): 71.4\n  Domain Average: 18.3\n  Lucidity Penalty: 97.1\n  LS: 53.3 (Rank: 4)\n\nmistral:7b:\n  TruthfulQA: 53.3\n  HHEM (normalized): 74.3\n  Domain Average: 26.0\n  Lucidity Penalty: 98.2\n  LS: 56.9 (Rank: 2)\n\nllama3:8b:\n  TruthfulQA: 56.0\n  HHEM (normalized): 100.0\n  Domain Average: 23.3\n  Lucidity Penalty: 100.0\n  LS: 62.2 (Rank: 1)\n\ngemma:7b:\n  TruthfulQA: 50.0\n  HHEM (normalized): 27.1\n  Domain Average: 17.2\n  Lucidity Penalty: 97.3\n  LS: 43.4 (Rank: 5)\n\nqwen2.5:3b:\n  TruthfulQA: 51.3\n  HHEM (normalized): 61.4\n  Domain Average: 27.5\n  Lucidity Penalty: 100.0\n  LS: 54.7 (Rank: 3)\n\n==================================================\nFinal LS Rankings:\n==================================================\n1. llama3:8b: 62.2\n2. mistral:7b: 56.9\n3. qwen2.5:3b: 54.7\n4. deepseek-llm: 53.3\n5. gemma:7b: 43.4\n","output_type":"stream"}],"execution_count":2}]}