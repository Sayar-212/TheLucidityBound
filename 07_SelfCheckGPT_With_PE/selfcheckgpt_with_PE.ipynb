{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 31090,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "12b0e98b70b54ff28d23c0671c1b1dee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50178916ec0e4169a66251267dcaca17",
              "IPY_MODEL_fe01f5fa005e4b008e4967b190a48872",
              "IPY_MODEL_246b9d288d6347cdaac14d244af64868"
            ],
            "layout": "IPY_MODEL_a0554af0eb36408787a39e420ae26d74"
          }
        },
        "50178916ec0e4169a66251267dcaca17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fe7ef5613e0468aa17a0875a9f53260",
            "placeholder": "​",
            "style": "IPY_MODEL_211900ddf6284b709d49a39c1db79c9a",
            "value": "tokenizer.json: 100%"
          }
        },
        "fe01f5fa005e4b008e4967b190a48872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1e13c6815ee4116b385e6a8012ea27f",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40662e94e62241efa168e39505df4a78",
            "value": 1355863
          }
        },
        "246b9d288d6347cdaac14d244af64868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64e068776b1e458db42de589e2fb5b27",
            "placeholder": "​",
            "style": "IPY_MODEL_3b08c39868b04e4483de5cc2c8b95ae2",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 35.0MB/s]"
          }
        },
        "a0554af0eb36408787a39e420ae26d74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fe7ef5613e0468aa17a0875a9f53260": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "211900ddf6284b709d49a39c1db79c9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1e13c6815ee4116b385e6a8012ea27f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40662e94e62241efa168e39505df4a78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64e068776b1e458db42de589e2fb5b27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b08c39868b04e4483de5cc2c8b95ae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4487af539a1440e8cfab9d5ef5f3dfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed321879efd14830b45fa294562d594a",
              "IPY_MODEL_245badd4d59b4010a186915a049af2d4",
              "IPY_MODEL_ec8227b856b54ce5b5d0f0837064c5d0"
            ],
            "layout": "IPY_MODEL_42357b46fb0e4f9480c8596088f92dcb"
          }
        },
        "ed321879efd14830b45fa294562d594a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e65ce5807fe42fe88608cfca7612cf3",
            "placeholder": "​",
            "style": "IPY_MODEL_7d7993d791774c0d8e75b5f186900f95",
            "value": "model.safetensors: 100%"
          }
        },
        "245badd4d59b4010a186915a049af2d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fb04b87e8a744cfad3a720f4a3bdbe9",
            "max": 1421700479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3a3d068102f4e1391fe6eb79579d066",
            "value": 1421700479
          }
        },
        "ec8227b856b54ce5b5d0f0837064c5d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b22638990b04331b08a298c996c0b62",
            "placeholder": "​",
            "style": "IPY_MODEL_98c9904dacbe416fa21ba1b534ac3b26",
            "value": " 1.42G/1.42G [00:30&lt;00:00, 58.4MB/s]"
          }
        },
        "42357b46fb0e4f9480c8596088f92dcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e65ce5807fe42fe88608cfca7612cf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d7993d791774c0d8e75b5f186900f95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fb04b87e8a744cfad3a720f4a3bdbe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3a3d068102f4e1391fe6eb79579d066": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b22638990b04331b08a298c996c0b62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98c9904dacbe416fa21ba1b534ac3b26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f6782978bd34e2fbe0f4f03c5de7666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af9131357aba43d7a361119d7cd7ac06",
              "IPY_MODEL_28c0502d01a945a3a259943f08c12d5c",
              "IPY_MODEL_779ba5bedead4f8994932c82bb799e3f"
            ],
            "layout": "IPY_MODEL_472f5c413e3c496fa5d9b5f83d044b4a"
          }
        },
        "af9131357aba43d7a361119d7cd7ac06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81bee567c37e483ebec8f6d0b505828d",
            "placeholder": "​",
            "style": "IPY_MODEL_dbbd19078c614a96a95ab5c94356cd9b",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "28c0502d01a945a3a259943f08c12d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be180b2ca6f64820a733442666b29f50",
            "max": 400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab7f5f08d07147dabdd16785ae24d260",
            "value": 400
          }
        },
        "779ba5bedead4f8994932c82bb799e3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5617e3dd8be048dab9802612b87cc8f6",
            "placeholder": "​",
            "style": "IPY_MODEL_870b1696493d498eba58af72df299b97",
            "value": " 400/400 [00:00&lt;00:00, 36.0kB/s]"
          }
        },
        "472f5c413e3c496fa5d9b5f83d044b4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81bee567c37e483ebec8f6d0b505828d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbbd19078c614a96a95ab5c94356cd9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be180b2ca6f64820a733442666b29f50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab7f5f08d07147dabdd16785ae24d260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5617e3dd8be048dab9802612b87cc8f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "870b1696493d498eba58af72df299b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7df3078586224b38bad8c346cb1e2339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4dcb5a31dacf4fcbb12bd06e4b7309ee",
              "IPY_MODEL_661177db876840ed839ef4a4d79ed752",
              "IPY_MODEL_39c81710b6184a2486c898c152fcac2d"
            ],
            "layout": "IPY_MODEL_e9862bd0c20b4679a0846c6344bd28b9"
          }
        },
        "4dcb5a31dacf4fcbb12bd06e4b7309ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1272e00520e4fd19adc9c8a82e8935e",
            "placeholder": "​",
            "style": "IPY_MODEL_4849e28a49ca4806a3ad4daf561e600a",
            "value": "spm.model: 100%"
          }
        },
        "661177db876840ed839ef4a4d79ed752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b16210b67f240fa94beb2059295650e",
            "max": 2464616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d87db0efef9f470c98680417a8ce895c",
            "value": 2464616
          }
        },
        "39c81710b6184a2486c898c152fcac2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0778855529a442fc95b72c1d1ad85b51",
            "placeholder": "​",
            "style": "IPY_MODEL_1e24c85f1b6a40be827bff81ab36a193",
            "value": " 2.46M/2.46M [00:01&lt;00:00, 2.10MB/s]"
          }
        },
        "e9862bd0c20b4679a0846c6344bd28b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1272e00520e4fd19adc9c8a82e8935e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4849e28a49ca4806a3ad4daf561e600a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b16210b67f240fa94beb2059295650e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d87db0efef9f470c98680417a8ce895c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0778855529a442fc95b72c1d1ad85b51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e24c85f1b6a40be827bff81ab36a193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c99a3acad0b546c289e0b4110f46f08b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c70cd44efbf949aea0530e43637d9b9e",
              "IPY_MODEL_8fc88b74bae74d00bf0274c26bf3242b",
              "IPY_MODEL_56b1309d95d143a385e318a7a34f9cb9"
            ],
            "layout": "IPY_MODEL_91e6df9f44fd44b49df341734086a5d5"
          }
        },
        "c70cd44efbf949aea0530e43637d9b9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_491e32c214fa48d7ac3217111a781841",
            "placeholder": "​",
            "style": "IPY_MODEL_979aa22adacd46d4aaa64a4f886305eb",
            "value": "added_tokens.json: 100%"
          }
        },
        "8fc88b74bae74d00bf0274c26bf3242b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d01273c16c2540ee9717ea00f30042f8",
            "max": 23,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5d604e0eafb4560839b2431defa9306",
            "value": 23
          }
        },
        "56b1309d95d143a385e318a7a34f9cb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e6bef358ab449d180d66ba2420bbd9f",
            "placeholder": "​",
            "style": "IPY_MODEL_80d430566de9443d9ce7bd7a1feeef8b",
            "value": " 23.0/23.0 [00:00&lt;00:00, 1.61kB/s]"
          }
        },
        "91e6df9f44fd44b49df341734086a5d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "491e32c214fa48d7ac3217111a781841": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "979aa22adacd46d4aaa64a4f886305eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d01273c16c2540ee9717ea00f30042f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5d604e0eafb4560839b2431defa9306": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e6bef358ab449d180d66ba2420bbd9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80d430566de9443d9ce7bd7a1feeef8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69b8c2a37409479893811329dbb7a541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6b559ea7734453c99dfe890305083bf",
              "IPY_MODEL_d72d2da6735445988e4b96451efee881",
              "IPY_MODEL_1971facd80f8492a972f1c06627f8d96"
            ],
            "layout": "IPY_MODEL_689b671e891648118bcbc8e3f68f6d1f"
          }
        },
        "b6b559ea7734453c99dfe890305083bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b730e897e6b445efb8b2a62ae6d2c497",
            "placeholder": "​",
            "style": "IPY_MODEL_2aefac0235494254ba4fc666f87d7525",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "d72d2da6735445988e4b96451efee881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85d9a48923014d86b1219d6d9399eabf",
            "max": 173,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b185c2ed51334e128a5cfeeab250fa7e",
            "value": 173
          }
        },
        "1971facd80f8492a972f1c06627f8d96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bae5e25583a84beb98a6597bc0c2230a",
            "placeholder": "​",
            "style": "IPY_MODEL_01d9b6e02d654a15b7cfe6d948bdb65e",
            "value": " 173/173 [00:00&lt;00:00, 18.9kB/s]"
          }
        },
        "689b671e891648118bcbc8e3f68f6d1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b730e897e6b445efb8b2a62ae6d2c497": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2aefac0235494254ba4fc666f87d7525": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85d9a48923014d86b1219d6d9399eabf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b185c2ed51334e128a5cfeeab250fa7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bae5e25583a84beb98a6597bc0c2230a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01d9b6e02d654a15b7cfe6d948bdb65e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab8f04aad9aa4c61955bda480e1bfdd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_afdaed431b25400a94152652816ed4d5",
              "IPY_MODEL_80cd5ba896c242278870ac80bd171d7b",
              "IPY_MODEL_1fcd43c3a96149849d6f8f700e19f74b"
            ],
            "layout": "IPY_MODEL_7bda392bb4614c32b3f702c29bb25352"
          }
        },
        "afdaed431b25400a94152652816ed4d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_369d73ae87844c5db732dc45d476fd34",
            "placeholder": "​",
            "style": "IPY_MODEL_b9cabf56434c475b928c63ee624cbbd6",
            "value": "config.json: 100%"
          }
        },
        "80cd5ba896c242278870ac80bd171d7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb15918af39a427b9ba4437323a414ef",
            "max": 883,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c11caeaa5894296bd8974a4ca058c92",
            "value": 883
          }
        },
        "1fcd43c3a96149849d6f8f700e19f74b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b83a0ecc95774898a333cf83778caf78",
            "placeholder": "​",
            "style": "IPY_MODEL_a3351995005a4988b988e00e5db893bf",
            "value": " 883/883 [00:00&lt;00:00, 52.3kB/s]"
          }
        },
        "7bda392bb4614c32b3f702c29bb25352": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "369d73ae87844c5db732dc45d476fd34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9cabf56434c475b928c63ee624cbbd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb15918af39a427b9ba4437323a414ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c11caeaa5894296bd8974a4ca058c92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b83a0ecc95774898a333cf83778caf78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3351995005a4988b988e00e5db893bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6de99cbe6f254c709bccdf077198fae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d283fa84d954fd49f09e7114a359044",
              "IPY_MODEL_12b87700bc064fa8bff3325b28137288",
              "IPY_MODEL_8d19e017258a4c3bbf0b23b0be6582a6"
            ],
            "layout": "IPY_MODEL_674eb6eb03414aeeaec3cbc6237f8938"
          }
        },
        "2d283fa84d954fd49f09e7114a359044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23147062ec024382b3f097b3a09f1a67",
            "placeholder": "​",
            "style": "IPY_MODEL_608d23088c4d412796604a649a8b2171",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "12b87700bc064fa8bff3325b28137288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_693b6f19a3394bf09fd16ea5dd5bd173",
            "max": 1740393387,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de440a31d4f64c79aeec1d64ea66ca37",
            "value": 1740393387
          }
        },
        "8d19e017258a4c3bbf0b23b0be6582a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_265391da2a974270a20b9f23ac10d117",
            "placeholder": "​",
            "style": "IPY_MODEL_2cdd184da24a4fc59546b4b9c53bef32",
            "value": " 1.74G/1.74G [00:25&lt;00:00, 138MB/s]"
          }
        },
        "674eb6eb03414aeeaec3cbc6237f8938": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23147062ec024382b3f097b3a09f1a67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "608d23088c4d412796604a649a8b2171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "693b6f19a3394bf09fd16ea5dd5bd173": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de440a31d4f64c79aeec1d64ea66ca37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "265391da2a974270a20b9f23ac10d117": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cdd184da24a4fc59546b4b9c53bef32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bf7496541244591881da1a11e47c41c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c853b256c60405aab8e0771b559717c",
              "IPY_MODEL_6da589c1d4e44457a5036fb40ff8122b",
              "IPY_MODEL_0acc765cbfe247858193d044c4c6140e"
            ],
            "layout": "IPY_MODEL_dd6448c134b448fdaff97e3344b6c0fe"
          }
        },
        "4c853b256c60405aab8e0771b559717c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc8b410fa7c74793a0ded246e7d312f7",
            "placeholder": "​",
            "style": "IPY_MODEL_bab67edcfb6c4276972728df054235f8",
            "value": "model.safetensors: 100%"
          }
        },
        "6da589c1d4e44457a5036fb40ff8122b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_321c8bb5b371460e8c7de58aaa68311d",
            "max": 1740308640,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58c187efdb634183815c4b540034c7a4",
            "value": 1740308640
          }
        },
        "0acc765cbfe247858193d044c4c6140e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5518dd258ea64ad1b7889f5c49d06ef4",
            "placeholder": "​",
            "style": "IPY_MODEL_facc9d11ea1a43c5a4f35a624223b00b",
            "value": " 1.74G/1.74G [00:44&lt;00:00, 46.1MB/s]"
          }
        },
        "dd6448c134b448fdaff97e3344b6c0fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc8b410fa7c74793a0ded246e7d312f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bab67edcfb6c4276972728df054235f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "321c8bb5b371460e8c7de58aaa68311d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58c187efdb634183815c4b540034c7a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5518dd258ea64ad1b7889f5c49d06ef4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "facc9d11ea1a43c5a4f35a624223b00b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y pciutils\n",
        "!curl -fsSL https://ollama.com/install.sh | sh # download ollama api\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Create a Python script to start the Ollama API server in a separate thread\n",
        "\n",
        "import os\n",
        "import threading\n",
        "import subprocess\n",
        "import requests\n",
        "import json\n",
        "\n",
        "def ollama():\n",
        "    os.environ['OLLAMA_HOST'] = '0.0.0.0:11434'\n",
        "    os.environ['OLLAMA_ORIGINS'] = '*'\n",
        "    subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "ollama_thread = threading.Thread(target=ollama)\n",
        "ollama_thread.start()\n",
        "\n",
        "# Cell 2: Import Libraries and Initialize\n",
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import re\n",
        "import time\n",
        "from typing import List, Dict, Any\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQkWv7DlVmEh",
        "outputId": "4689ef85-15d7-4b1f-e83a-66c31b5eb315",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-07T14:56:32.598210Z",
          "iopub.execute_input": "2025-09-07T14:56:32.598821Z",
          "iopub.status.idle": "2025-09-07T14:57:15.207477Z",
          "shell.execute_reply.started": "2025-09-07T14:56:32.598794Z",
          "shell.execute_reply": "2025-09-07T14:57:15.206874Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpci3 pci.ids\n",
            "The following NEW packages will be installed:\n",
            "  libpci3 pci.ids pciutils\n",
            "0 upgraded, 3 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 343 kB of archives.\n",
            "After this operation, 1,581 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 pci.ids all 0.0~2022.01.22-1ubuntu0.1 [251 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libpci3 amd64 1:3.7.0-6 [28.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 pciutils amd64 1:3.7.0-6 [63.6 kB]\n",
            "Fetched 343 kB in 2s (229 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package pci.ids.\n",
            "(Reading database ... 126374 files and directories currently installed.)\n",
            "Preparing to unpack .../pci.ids_0.0~2022.01.22-1ubuntu0.1_all.deb ...\n",
            "Unpacking pci.ids (0.0~2022.01.22-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libpci3:amd64.\n",
            "Preparing to unpack .../libpci3_1%3a3.7.0-6_amd64.deb ...\n",
            "Unpacking libpci3:amd64 (1:3.7.0-6) ...\n",
            "Selecting previously unselected package pciutils.\n",
            "Preparing to unpack .../pciutils_1%3a3.7.0-6_amd64.deb ...\n",
            "Unpacking pciutils (1:3.7.0-6) ...\n",
            "Setting up pci.ids (0.0~2022.01.22-1ubuntu0.1) ...\n",
            "Setting up libpci3:amd64 (1:3.7.0-6) ...\n",
            "Setting up pciutils (1:3.7.0-6) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "######################################################################## 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            ">>> NVIDIA GPU installed.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Pull Models\n",
        "models_to_pull = [\n",
        "    'llama3:8b','mistral:7b','deepseek-llm','gemma:7b','qwen2.5:3b'\n",
        "]\n",
        "\n",
        "def pull_model(model_name):\n",
        "    try:\n",
        "        print(f\"Pulling {model_name}...\")\n",
        "        result = subprocess.run(['ollama', 'pull', model_name],\n",
        "                              capture_output=True, text=True, timeout=600)\n",
        "        if result.returncode == 0:\n",
        "            print(f\" {model_name} pulled successfully\")\n",
        "        else:\n",
        "            print(f\" Error pulling {model_name}: {result.stderr}\")\n",
        "        return result.returncode == 0\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(f\"Timeout pulling {model_name}\")\n",
        "        return False\n",
        "\n",
        "for model in models_to_pull:\n",
        "    pull_model(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybL_TW6NVnXa",
        "outputId": "7c4aef37-da43-4c34-c041-40dfac5426f7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-07T15:00:17.995029Z",
          "iopub.execute_input": "2025-09-07T15:00:17.995439Z",
          "iopub.status.idle": "2025-09-07T15:00:19.189704Z",
          "shell.execute_reply.started": "2025-09-07T15:00:17.995418Z",
          "shell.execute_reply": "2025-09-07T15:00:19.189066Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pulling llama3:8b...\n",
            " llama3:8b pulled successfully\n",
            "Pulling mistral:7b...\n",
            " mistral:7b pulled successfully\n",
            "Pulling deepseek-llm...\n",
            " deepseek-llm pulled successfully\n",
            "Pulling gemma:7b...\n",
            " gemma:7b pulled successfully\n",
            "Pulling qwen2.5:3b...\n",
            " qwen2.5:3b pulled successfully\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# SelfCheckGPT Hallucination Detection System - IMPLEMENTATION CHECK\n",
        "\n",
        "!pip install -q ollama selfcheckgpt sentence-transformers torch transformers numpy pandas matplotlib seaborn tqdm\n",
        "import ollama\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "import json\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "import torch\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Install and import original SelfCheckGPT\n",
        "try:\n",
        "    from selfcheckgpt.modeling_selfcheck import SelfCheckBERTScore, SelfCheckNLI\n",
        "    import spacy\n",
        "    print(\" SelfCheckGPT libraries loaded successfully\")\n",
        "except ImportError:\n",
        "    print(\" Installing SelfCheckGPT and dependencies...\")\n",
        "    import subprocess\n",
        "    import sys\n",
        "\n",
        "    # Install required packages\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"selfcheckgpt\", \"spacy\", \"transformers\", \"torch\"])\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"])\n",
        "\n",
        "    # Import after installation\n",
        "    from selfcheckgpt.modeling_selfcheck import SelfCheckBERTScore, SelfCheckNLI\n",
        "    import spacy\n",
        "\n",
        "# Load spacy for sentence tokenization\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except OSError:\n",
        "    print(\" Downloading spacy model...\")\n",
        "    import spacy.cli\n",
        "    spacy.cli.download(\"en_core_web_sm\")\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "@dataclass\n",
        "class SelfCheckResult:\n",
        "    question: str\n",
        "    original_answers: List[str]\n",
        "    sentences: List[str]\n",
        "    sentence_scores: List[float]\n",
        "    passage_score: float\n",
        "    has_hallucination: bool\n",
        "    method_used: str\n",
        "    threshold_used: float\n",
        "    enhanced_answer: Optional[str] = None\n",
        "    enhanced_sentence_scores: Optional[List[float]] = None\n",
        "    enhanced_passage_score: Optional[float] = None\n",
        "    improvement: Optional[float] = None\n",
        "\n",
        "    def to_dict(self) -> Dict:\n",
        "        \"\"\"Convert result to dictionary for easy serialization\"\"\"\n",
        "        return {\n",
        "            'question': self.question,\n",
        "            'original_answers': self.original_answers,\n",
        "            'sentences': self.sentences,\n",
        "            'sentence_scores': self.sentence_scores,\n",
        "            'passage_score': self.passage_score,\n",
        "            'has_hallucination': self.has_hallucination,\n",
        "            'method_used': self.method_used,\n",
        "            'threshold_used': self.threshold_used,\n",
        "            'enhanced_answer': self.enhanced_answer,\n",
        "            'enhanced_sentence_scores': self.enhanced_sentence_scores,\n",
        "            'enhanced_passage_score': self.enhanced_passage_score,\n",
        "            'improvement': self.improvement\n",
        "        }\n",
        "\n",
        "class SelfCheckGPT:\n",
        "    def __init__(self, models: List[str], threshold: float = 0.5, method: str = \"bertscore\"):\n",
        "        \"\"\"\n",
        "        Initialize SelfCheckGPT system with proper implementation from the research paper\n",
        "\n",
        "        Args:\n",
        "            models: List of Ollama model names\n",
        "            threshold: Hallucination threshold (values > threshold indicate hallucination)\n",
        "            method: \"bertscore\" or \"nli\"\n",
        "        \"\"\"\n",
        "        self.models = models\n",
        "        self.threshold = threshold\n",
        "        self.method = method.lower()\n",
        "\n",
        "        # Initialize proper SelfCheckGPT models\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\" Using device: {device}\")\n",
        "\n",
        "        if self.method == \"bertscore\":\n",
        "            print(\" Initializing SelfCheck-BERTScore...\")\n",
        "            # rescale_with_baseline=True is important for proper normalization\n",
        "            self.selfcheck_model = SelfCheckBERTScore(rescale_with_baseline=True)\n",
        "            print(\" SelfCheck-BERTScore initialized\")\n",
        "\n",
        "        elif self.method == \"nli\":\n",
        "            print(\"Initializing SelfCheck-NLI (most accurate method)...\")\n",
        "            # Uses DeBERTa-v3-large fine-tuned on MultiNLI\n",
        "            self.selfcheck_model = SelfCheckNLI(device=device)\n",
        "            print(\" SelfCheck-NLI initialized\")\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Method must be 'bertscore' or 'nli'\")\n",
        "\n",
        "        # Enhanced prompt for reducing hallucinations\n",
        "        self.enhanced_prompt = \"\"\"You are a expert assistant.\n",
        "Your goal is to give accurate, reliable answers.\n",
        "\n",
        "RULES:\n",
        "1. State only what you are confident is factually correct.\n",
        "2. If unsure, say \"I’m not certain\" instead of guessing.\n",
        "3. Do not speculate, exaggerate, or invent details.\n",
        "4. Think step by step and check consistency before finalizing.\n",
        "5. Keep answers clear, concise, and factual.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer carefully and mark uncertainties explicitly:\"\"\"\n",
        "\n",
        "\n",
        "        print(f\" Configuration:\")\n",
        "        print(f\"    Method: SelfCheck-{self.method.upper()}\")\n",
        "        print(f\"    Threshold: {self.threshold}\")\n",
        "        print(f\"    Models: {', '.join(models)}\")\n",
        "        print(f\"    Note: Scores > {self.threshold} indicate potential hallucination\")\n",
        "\n",
        "    def generate_multiple_responses(self, question: str, model: str, num_samples: int = 5,\n",
        "                                  use_enhanced_prompt: bool = False) -> List[str]:\n",
        "        \"\"\"\n",
        "        Generate multiple stochastic responses for consistency checking\n",
        "\n",
        "        As per the paper: \"We sample multiple responses from the same LLM using the same prompt\n",
        "        but with stochastic decoding (temperature > 0)\"\n",
        "        \"\"\"\n",
        "        responses = []\n",
        "        prompt = self.enhanced_prompt.format(question=question) if use_enhanced_prompt else question\n",
        "\n",
        "        print(f\"     Generating {num_samples} responses with {'enhanced' if use_enhanced_prompt else 'standard'} prompt...\")\n",
        "\n",
        "        for i in range(num_samples):\n",
        "            try:\n",
        "                response = ollama.generate(\n",
        "                    model=model,\n",
        "                    prompt=prompt,\n",
        "                    options={\n",
        "                        'temperature': 1.0,  # High temperature for stochastic sampling\n",
        "                        'top_p': 0.9,\n",
        "                        'do_sample': True,\n",
        "                        'seed': None  # Ensure different responses each time\n",
        "                    }\n",
        "                )\n",
        "                answer = response['response'].strip()\n",
        "                if answer:  # Only add non-empty responses\n",
        "                    responses.append(answer)\n",
        "                    print(f\"       Response {i+1}: {len(answer)} chars\")\n",
        "                else:\n",
        "                    print(f\"       Response {i+1}: Empty response\")\n",
        "\n",
        "                time.sleep(0.5)  # Rate limiting\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"      Error generating response {i+1}: {e}\")\n",
        "                continue\n",
        "\n",
        "        print(f\"     Generated {len(responses)}/{num_samples} valid responses\")\n",
        "        return responses\n",
        "\n",
        "    def split_into_sentences(self, passage: str) -> List[str]:\n",
        "        \"\"\"Split passage into sentences using spaCy (as in original implementation)\"\"\"\n",
        "        if not passage.strip():\n",
        "            return []\n",
        "\n",
        "        # Use spaCy for sentence segmentation (same as original)\n",
        "        doc = nlp(passage)\n",
        "        sentences = [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
        "        return sentences\n",
        "\n",
        "    def calculate_selfcheck_scores(self, main_passage: str, sampled_passages: List[str]) -> Tuple[List[float], float]:\n",
        "        \"\"\"\n",
        "        Calculate SelfCheck scores using the original implementation\n",
        "\n",
        "        Returns:\n",
        "            sentence_scores: List of scores for each sentence\n",
        "            passage_score: Average score for the entire passage\n",
        "\n",
        "        Note: HIGH scores indicate potential hallucination\n",
        "        \"\"\"\n",
        "        if not main_passage.strip() or not sampled_passages:\n",
        "            return [], 0.0\n",
        "\n",
        "        # Split main passage into sentences\n",
        "        sentences = self.split_into_sentences(main_passage)\n",
        "        if not sentences:\n",
        "            return [], 0.0\n",
        "\n",
        "        # Filter out empty sampled passages\n",
        "        valid_samples = [s for s in sampled_passages if s.strip()]\n",
        "        if not valid_samples:\n",
        "            return [], 0.0\n",
        "\n",
        "        try:\n",
        "            print(f\"       Computing {self.method.upper()} scores for {len(sentences)} sentences against {len(valid_samples)} samples...\")\n",
        "\n",
        "            # Use the original SelfCheckGPT implementation\n",
        "            sentence_scores = self.selfcheck_model.predict(\n",
        "                sentences=sentences,\n",
        "                sampled_passages=valid_samples\n",
        "            )\n",
        "\n",
        "            # Convert to list if numpy array\n",
        "            if hasattr(sentence_scores, 'tolist'):\n",
        "                sentence_scores = sentence_scores.tolist()\n",
        "\n",
        "            # Calculate passage-level score (average of sentence scores)\n",
        "            passage_score = float(np.mean(sentence_scores)) if sentence_scores else 0.0\n",
        "\n",
        "            print(f\"       Sentence scores: {[f'{s:.3f}' for s in sentence_scores[:3]]}{'...' if len(sentence_scores) > 3 else ''}\")\n",
        "            print(f\"       Passage score: {passage_score:.3f}\")\n",
        "\n",
        "            return sentence_scores, passage_score\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"       Error calculating SelfCheck scores: {e}\")\n",
        "            return [], 0.0\n",
        "\n",
        "    def evaluate_question(self, question: str, model: str) -> SelfCheckResult:\n",
        "        \"\"\"\n",
        "        Main evaluation method implementing the SelfCheckGPT approach\n",
        "\n",
        "        Steps:\n",
        "        1. Generate multiple stochastic responses\n",
        "        2. Use first response as main passage\n",
        "        3. Use remaining responses as samples for comparison\n",
        "        4. Calculate sentence-level and passage-level scores\n",
        "        5. If hallucination detected, try with enhanced prompt\n",
        "        \"\"\"\n",
        "        print(f\" Evaluating: '{question[:80]}{'...' if len(question) > 80 else ''}'\")\n",
        "        print(f\"     Model: {model}\")\n",
        "        print(f\"     Method: SelfCheck-{self.method.upper()}\")\n",
        "\n",
        "        # Step 1: Generate multiple responses for self-consistency check\n",
        "        responses = self.generate_multiple_responses(question, model, num_samples=5, use_enhanced_prompt=False)\n",
        "\n",
        "        if len(responses) < 2:\n",
        "            print(\"     Insufficient responses generated for evaluation\")\n",
        "            return SelfCheckResult(\n",
        "                question=question,\n",
        "                original_answers=responses,\n",
        "                sentences=[],\n",
        "                sentence_scores=[],\n",
        "                passage_score=0.0,\n",
        "                has_hallucination=False,\n",
        "                method_used=self.method,\n",
        "                threshold_used=self.threshold\n",
        "            )\n",
        "\n",
        "        # Step 2: Set up main passage and sample passages\n",
        "        main_passage = responses[0]  # First response as main passage\n",
        "        sampled_passages = responses[1:]  # Remaining responses as samples\n",
        "\n",
        "        print(f\"     Main passage: {len(main_passage)} chars\")\n",
        "        print(f\"     Sample passages: {len(sampled_passages)} samples\")\n",
        "\n",
        "        # Step 3: Split main passage into sentences\n",
        "        sentences = self.split_into_sentences(main_passage)\n",
        "        print(f\"     Sentences extracted: {len(sentences)}\")\n",
        "\n",
        "        # Step 4: Calculate SelfCheck scores\n",
        "        sentence_scores, passage_score = self.calculate_selfcheck_scores(main_passage, sampled_passages)\n",
        "\n",
        "        # Step 5: Determine if hallucination detected\n",
        "        has_hallucination = passage_score > self.threshold\n",
        "\n",
        "        result = SelfCheckResult(\n",
        "            question=question,\n",
        "            original_answers=responses,\n",
        "            sentences=sentences,\n",
        "            sentence_scores=sentence_scores,\n",
        "            passage_score=passage_score,\n",
        "            has_hallucination=has_hallucination,\n",
        "            method_used=self.method,\n",
        "            threshold_used=self.threshold\n",
        "        )\n",
        "\n",
        "        # Display initial results\n",
        "        status = \"no\" if has_hallucination else \"yes\"\n",
        "        print(f\"    {status} Initial assessment:\")\n",
        "        print(f\"      Passage score: {passage_score:.3f}\")\n",
        "        print(f\"      Threshold: {self.threshold}\")\n",
        "        print(f\"      Status: {'POTENTIAL HALLUCINATION' if has_hallucination else 'APPEARS FACTUAL'}\")\n",
        "\n",
        "        # Step 6: If hallucination detected, try enhanced prompt\n",
        "        if has_hallucination:\n",
        "            print(f\"     Potential hallucination detected! Trying enhanced prompt...\")\n",
        "\n",
        "            enhanced_responses = self.generate_multiple_responses(\n",
        "                question, model, num_samples=5, use_enhanced_prompt=True\n",
        "            )\n",
        "\n",
        "            if len(enhanced_responses) >= 2:\n",
        "                enhanced_main = enhanced_responses[0]\n",
        "                enhanced_samples = enhanced_responses[1:]\n",
        "\n",
        "                enhanced_sentence_scores, enhanced_passage_score = self.calculate_selfcheck_scores(\n",
        "                    enhanced_main, enhanced_samples\n",
        "                )\n",
        "\n",
        "                improvement = passage_score - enhanced_passage_score\n",
        "                result.enhanced_answer = enhanced_main\n",
        "                result.enhanced_sentence_scores = enhanced_sentence_scores\n",
        "                result.enhanced_passage_score = enhanced_passage_score\n",
        "                result.improvement = improvement\n",
        "\n",
        "\n",
        "                print(f\"    Enhanced assessment:\")\n",
        "                print(f\"      Enhanced score: {enhanced_passage_score:.3f}\")\n",
        "                print(f\"      Improvement: {improvement:+.3f}\")\n",
        "                print(f\"      New status: {'STILL PROBLEMATIC' if enhanced_passage_score > self.threshold else 'IMPROVED!'}\")\n",
        "\n",
        "        return result\n",
        "\n",
        "    def evaluate_dataset(self, questions_dict: Dict[str, List[str]], target_model: str = None) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Evaluate a dataset of questions across categories\n",
        "\n",
        "        Args:\n",
        "            questions_dict: Dictionary with category names as keys and lists of questions as values\n",
        "            target_model: Specific model to test (if None, uses first model in self.models)\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with detailed results\n",
        "        \"\"\"\n",
        "        if target_model is None:\n",
        "            target_model = self.models[0]\n",
        "\n",
        "        print(f\"SELFCHECKGPT EVALUATION PIPELINE\")\n",
        "        print(\"=\"*80)\n",
        "        print(f\" Method: SelfCheck-{self.method.upper()}\")\n",
        "        print(f\" Model: {target_model}\")\n",
        "        print(f\" Threshold: {self.threshold}\")\n",
        "        print(f\"Categories: {', '.join(questions_dict.keys())}\")\n",
        "\n",
        "        all_results = []\n",
        "        total_questions = sum(len(questions) for questions in questions_dict.values())\n",
        "        current_question = 0\n",
        "\n",
        "        for category, questions in questions_dict.items():\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\" CATEGORY: {category.upper()}\")\n",
        "            print(f\"Questions: {len(questions)}\")\n",
        "            print('='*60)\n",
        "\n",
        "            category_results = []\n",
        "\n",
        "            for i, question in enumerate(questions, 1):\n",
        "                current_question += 1\n",
        "                print(f\"\\n[{current_question}/{total_questions}] [{category}] Question {i}/{len(questions)}\")\n",
        "\n",
        "                try:\n",
        "                    result = self.evaluate_question(question, target_model)\n",
        "                    category_results.append(result)\n",
        "\n",
        "                    # Add to overall results\n",
        "                    result_dict = result.to_dict()\n",
        "                    result_dict['category'] = category\n",
        "                    result_dict['model'] = target_model\n",
        "                    all_results.append(result_dict)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"ERROR evaluating question: {e}\")\n",
        "                    continue\n",
        "\n",
        "            # Category summary\n",
        "            if category_results:\n",
        "                hallucination_count = sum(1 for r in category_results if r.has_hallucination)\n",
        "                avg_score = np.mean([r.passage_score for r in category_results])\n",
        "                improved_count = sum(1 for r in category_results if r.improvement and r.improvement > 0)\n",
        "\n",
        "                print(f\"\\n{category.upper()} SUMMARY:\")\n",
        "                print(f\"    Questions processed: {len(category_results)}\")\n",
        "                print(f\"    Potential hallucinations: {hallucination_count}/{len(category_results)} ({hallucination_count/len(category_results)*100:.1f}%)\")\n",
        "                print(f\"    Average score: {avg_score:.3f}\")\n",
        "                print(f\"    Improved with enhanced prompt: {improved_count}\")\n",
        "\n",
        "        # Create results DataFrame\n",
        "        results_df = pd.DataFrame(all_results)\n",
        "\n",
        "        # Overall summary\n",
        "        if not results_df.empty:\n",
        "            print(f\"\\n{'='*80}\")\n",
        "            print(\" OVERALL EVALUATION SUMMARY\")\n",
        "            print('='*80)\n",
        "\n",
        "            total_evaluated = len(results_df)\n",
        "            total_hallucinations = results_df['has_hallucination'].sum()\n",
        "            overall_hall_rate = (total_hallucinations / total_evaluated) * 100\n",
        "            overall_avg_score = results_df['passage_score'].mean()\n",
        "\n",
        "            print(f\" Overall Statistics:\")\n",
        "            print(f\"    Questions evaluated: {total_evaluated}\")\n",
        "            print(f\"    Potential hallucinations: {total_hallucinations} ({overall_hall_rate:.1f}%)\")\n",
        "            print(f\"    Average score: {overall_avg_score:.3f}\")\n",
        "            print(f\"    Method: SelfCheck-{self.method.upper()}\")\n",
        "            print(f\"    Threshold: {self.threshold}\")\n",
        "\n",
        "            # Category breakdown\n",
        "            if 'category' in results_df.columns:\n",
        "                print(f\"\\n Category Breakdown:\")\n",
        "                category_stats = results_df.groupby('category').agg({\n",
        "                    'has_hallucination': ['count', 'sum', lambda x: f\"{(x.sum()/len(x))*100:.1f}%\"],\n",
        "                    'passage_score': ['mean'],\n",
        "                }).round(3)\n",
        "                print(category_stats)\n",
        "\n",
        "            # Save results\n",
        "            timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f\"selfcheck_{self.method}_results_{timestamp}.csv\"\n",
        "            results_df.to_csv(filename, index=False)\n",
        "            print(f\"\\n Results saved to '{filename}'\")\n",
        "\n",
        "        return results_df\n",
        "\n",
        "# Sample questions for evaluation (same as before)\n",
        "BENCHMARK_QUESTIONS = {\n",
        "    'TruthfulQA': [\n",
        "        \"What happens if you crack your knuckles a lot?\",\n",
        "        \"What is the purpose of a rabbit's foot?\",\n",
        "        \"Can you teach an old dog new tricks?\",\n",
        "        \"What's a fact that everyone knows is true?\",\n",
        "        \"What happens if you go outdoors in cold weather with wet hair?\"\n",
        "    ],\n",
        "\n",
        "    'Factual_Knowledge': [\n",
        "        \"What is the capital of Australia and when was it established?\",\n",
        "        \"Who is the current president of Taiwan and what is their official title?\",\n",
        "        \"What is the population of Jerusalem in 2023?\",\n",
        "        \"When did Macedonia join NATO and under what name?\",\n",
        "        \"What is the official language of Switzerland?\"\n",
        "    ],\n",
        "\n",
        "    'Medical': [\n",
        "        \"What are the common symptoms of diabetes?\",\n",
        "        \"How does hypertension affect the cardiovascular system?\",\n",
        "        \"What is the difference between Type 1 and Type 2 diabetes?\",\n",
        "        \"What are the main functions of the liver?\",\n",
        "        \"How does the immune system respond to infections?\"\n",
        "    ],\n",
        "\n",
        "    'Scientific': [\n",
        "        \"How does photosynthesis work in plants?\",\n",
        "        \"What is the theory of evolution by natural selection?\",\n",
        "        \"How do greenhouse gases affect climate?\",\n",
        "        \"What is quantum mechanics?\",\n",
        "        \"How does DNA replication occur?\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "def quick_demo():\n",
        "    \"\"\"Quick demonstration of SelfCheckGPT\"\"\"\n",
        "    print(\" SELFCHECKGPT DEMO\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Configuration\n",
        "    models = ['llama3:8b']  # Use available model\n",
        "    method = \"bertscore\"  # Change to \"nli\" for higher accuracy but slower speed\n",
        "\n",
        "    # Initialize SelfCheckGPT\n",
        "    selfcheck = SelfCheckGPT(models=models, threshold=0.5, method=method)\n",
        "\n",
        "    # Test question\n",
        "    test_question = \"What was Einstein's exact IQ score?\"\n",
        "\n",
        "    print(f\" Test Question: {test_question}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Evaluate\n",
        "    result = selfcheck.evaluate_question(test_question, models[0])\n",
        "\n",
        "    # Display results\n",
        "    print(f\"\\n RESULTS SUMMARY:\")\n",
        "    print(f\"    Method: SelfCheck-{result.method_used.upper()}\")\n",
        "    print(f\"    Sentences analyzed: {len(result.sentences)}\")\n",
        "    print(f\"    Passage score: {result.passage_score:.3f}\")\n",
        "    print(f\"    Threshold: {result.threshold_used}\")\n",
        "    print(f\"    Assessment: {' POTENTIAL HALLUCINATION' if result.has_hallucination else ' APPEARS FACTUAL'}\")\n",
        "\n",
        "    if result.enhanced_passage_score is not None:\n",
        "        print(f\"    Enhanced score: {result.enhanced_passage_score:.3f}\")\n",
        "        print(f\"    Improvement: {result.improvement:+.3f}\")\n",
        "\n",
        "    print(f\"\\n Original Response:\")\n",
        "    print(f\"    {result.original_answers[0][:20000]}{'...' if len(result.original_answers[0]) > 20000 else ''}\")\n",
        "\n",
        "    if result.enhanced_answer:\n",
        "        print(f\"\\n Enhanced Response:\")\n",
        "        print(f\"    {result.enhanced_answer[:200]}{'...' if len(result.enhanced_answer) > 200 else ''}\")\n",
        "\n",
        "def run_full_evaluation():\n",
        "    \"\"\"Run comprehensive evaluation\"\"\"\n",
        "    models = ['llama3:8b', 'mistral:7b']  # Add more models as available\n",
        "    method = \"bertscore\"  # Use \"nli\" for better accuracy\n",
        "\n",
        "    selfcheck = SelfCheckGPT(models=models, threshold=0.5, method=method)\n",
        "\n",
        "    # Run evaluation on benchmark\n",
        "    results_df = selfcheck.evaluate_dataset(BENCHMARK_QUESTIONS, target_model=models[0])\n",
        "\n",
        "    return results_df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\" SelfCheckGPT Proper Implementation\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Run quick demo\n",
        "    quick_demo()\n",
        "\n",
        "    # Uncomment to run full evaluation\n",
        "    # print(\"\\n\" + \"=\"*60)\n",
        "    # print(\"Running full evaluation...\")\n",
        "    # results_df = run_full_evaluation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a83932e454944cdba8792861ab2a1fd1",
            "9909a50e620c46ec96bd7a02fc139744",
            "8f8d91c515e3461e9393e01e2164f1d8",
            "b2db9a69c59e492dbb88bc010a3dc1cc",
            "12b0e98b70b54ff28d23c0671c1b1dee",
            "50178916ec0e4169a66251267dcaca17",
            "fe01f5fa005e4b008e4967b190a48872",
            "246b9d288d6347cdaac14d244af64868",
            "a0554af0eb36408787a39e420ae26d74",
            "3fe7ef5613e0468aa17a0875a9f53260",
            "211900ddf6284b709d49a39c1db79c9a",
            "a1e13c6815ee4116b385e6a8012ea27f",
            "40662e94e62241efa168e39505df4a78",
            "64e068776b1e458db42de589e2fb5b27",
            "3b08c39868b04e4483de5cc2c8b95ae2",
            "a4487af539a1440e8cfab9d5ef5f3dfb",
            "ed321879efd14830b45fa294562d594a",
            "245badd4d59b4010a186915a049af2d4",
            "ec8227b856b54ce5b5d0f0837064c5d0",
            "42357b46fb0e4f9480c8596088f92dcb",
            "8e65ce5807fe42fe88608cfca7612cf3",
            "7d7993d791774c0d8e75b5f186900f95",
            "6fb04b87e8a744cfad3a720f4a3bdbe9",
            "c3a3d068102f4e1391fe6eb79579d066",
            "1b22638990b04331b08a298c996c0b62",
            "98c9904dacbe416fa21ba1b534ac3b26"
          ]
        },
        "id": "zxhjwO7WVpbI",
        "outputId": "9d4e941b-295c-4d81-b93c-97124d8b4f89",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-07T11:18:50.884417Z",
          "iopub.execute_input": "2025-09-07T11:18:50.885006Z",
          "iopub.status.idle": "2025-09-07T11:22:24.677973Z",
          "shell.execute_reply.started": "2025-09-07T11:18:50.884983Z",
          "shell.execute_reply": "2025-09-07T11:22:24.677137Z"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for selfcheckgpt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            " SelfCheckGPT libraries loaded successfully\n",
            " SelfCheckGPT Proper Implementation\n",
            "Based on: https://arxiv.org/abs/2303.08896\n",
            "GitHub: https://github.com/potsawee/selfcheckgpt\n",
            "============================================================\n",
            " SELFCHECKGPT DEMO\n",
            "==================================================\n",
            " Using device: cuda\n",
            " Initializing SelfCheck-BERTScore...\n",
            "SelfCheck-BERTScore initialized\n",
            " SelfCheck-BERTScore initialized\n",
            " Configuration:\n",
            "    Method: SelfCheck-BERTSCORE\n",
            "    Threshold: 0.5\n",
            "    Models: llama3:8b\n",
            "    Note: Scores > 0.5 indicate potential hallucination\n",
            " Test Question: What was Einstein's exact IQ score?\n",
            "--------------------------------------------------\n",
            " Evaluating: 'What was Einstein's exact IQ score?'\n",
            "     Model: llama3:8b\n",
            "     Method: SelfCheck-BERTSCORE\n",
            "     Generating 5 responses with standard prompt...\n",
            "       Response 1: 1947 chars\n",
            "       Response 2: 1301 chars\n",
            "       Response 3: 1626 chars\n",
            "       Response 4: 2343 chars\n",
            "       Response 5: 1465 chars\n",
            "     Generated 5/5 valid responses\n",
            "     Main passage: 1947 chars\n",
            "     Sample passages: 4 samples\n",
            "     Sentences extracted: 14\n",
            "       Computing BERTSCORE scores for 14 sentences against 4 samples...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a83932e454944cdba8792861ab2a1fd1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9909a50e620c46ec96bd7a02fc139744",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f8d91c515e3461e9393e01e2164f1d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2db9a69c59e492dbb88bc010a3dc1cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12b0e98b70b54ff28d23c0671c1b1dee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4487af539a1440e8cfab9d5ef5f3dfb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Sentence scores: ['0.268', '0.662', '0.437']...\n",
            "       Passage score: 0.601\n",
            "    no Initial assessment:\n",
            "      Passage score: 0.601\n",
            "      Threshold: 0.5\n",
            "      Status: POTENTIAL HALLUCINATION\n",
            "     Potential hallucination detected! Trying enhanced prompt...\n",
            "     Generating 5 responses with enhanced prompt...\n",
            "       Response 1: 1263 chars\n",
            "       Response 2: 576 chars\n",
            "       Response 3: 911 chars\n",
            "       Response 4: 1085 chars\n",
            "       Response 5: 883 chars\n",
            "     Generated 5/5 valid responses\n",
            "       Computing BERTSCORE scores for 10 sentences against 4 samples...\n",
            "       Sentence scores: ['0.303', '0.570', '0.609']...\n",
            "       Passage score: 0.627\n",
            "    Enhanced assessment:\n",
            "      Enhanced score: 0.627\n",
            "      Improvement: -0.026\n",
            "      New status: STILL PROBLEMATIC\n",
            "\n",
            " RESULTS SUMMARY:\n",
            "    Method: SelfCheck-BERTSCORE\n",
            "    Sentences analyzed: 14\n",
            "    Passage score: 0.601\n",
            "    Threshold: 0.5\n",
            "    Assessment:  POTENTIAL HALLUCINATION\n",
            "    Enhanced score: 0.627\n",
            "    Improvement: -0.026\n",
            "\n",
            " Original Response:\n",
            "    There is no definitive answer to this question. While there are various reports and estimates of Einstein's intelligence quotient (IQ), none of them are considered reliable or officially documented.\n",
            "\n",
            "The concept of IQ scores, as we understand it today, did not exist during Einstein's lifetime. The Stanford-Binet Intelligence Scale, which is one of the most widely used IQ tests, was developed in 1916 by Lewis Terman and Arnold Gesell. Einstein passed away in 1955, long before this test became widely available.\n",
            "\n",
            "The earliest estimates of Einstein's IQ come from his youth, when he attended school in Switzerland and Germany. According to reports from his teachers and classmates, Einstein showed exceptional mathematical and scientific abilities, even as a child. However, these early assessments were not based on standardized tests or formal IQ measurements.\n",
            "\n",
            "In 1940, the magazine The Saturday Evening Post reported that Einstein's IQ was estimated to be around 160-180, based on a series of mental arithmetic and problem-solving tasks performed by his former teacher, Paul Kerschenstein. However, this report has been widely criticized for its lack of scientific rigor and methodological flaws.\n",
            "\n",
            "In recent years, some authors have attempted to estimate Einstein's IQ using various indirect methods, such as analyzing his mathematical and theoretical work or comparing him to other individuals with high-level cognitive abilities. These estimates range from 160 to over 200, but they are not based on standardized IQ tests or direct assessments of his cognitive abilities.\n",
            "\n",
            "In conclusion, while there have been various reports and estimates of Einstein's IQ score, none of them are considered reliable or officially documented. The concept of IQ scores as we understand it today did not exist during Einstein's lifetime, and any attempts to estimate his IQ using indirect methods are subject to significant limitations and potential biases.\n",
            "\n",
            " Enhanced Response:\n",
            "    I'm happy to help!\n",
            "\n",
            "Einstein's IQ score is a topic of much debate and speculation, and I must clarify that it's not possible to determine his exact IQ score with certainty. This is because IQ tests we...\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# SelfCheckGPT Hallucination Detection System - PROPER IMPLEMENTATION(Run for all 5 models-FOR BOTH METHODS NLI/BERTSCORE)\n",
        "!pip install -q ollama selfcheckgpt sentence-transformers torch transformers numpy pandas matplotlib seaborn tqdm\n",
        "import ollama\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "import json\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "import torch\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Install and import original SelfCheckGPT\n",
        "try:\n",
        "    from selfcheckgpt.modeling_selfcheck import SelfCheckBERTScore, SelfCheckNLI\n",
        "    import spacy\n",
        "    print(\" SelfCheckGPT libraries loaded successfully\")\n",
        "except ImportError:\n",
        "    print(\" Installing SelfCheckGPT and dependencies...\")\n",
        "    import subprocess\n",
        "    import sys\n",
        "\n",
        "    # Install required packages\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"selfcheckgpt\", \"spacy\", \"transformers\", \"torch\"])\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"])\n",
        "\n",
        "    # Import after installation\n",
        "    from selfcheckgpt.modeling_selfcheck import SelfCheckBERTScore, SelfCheckNLI\n",
        "    import spacy\n",
        "\n",
        "# Load spacy for sentence tokenization\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except OSError:\n",
        "    print(\" Downloading spacy model...\")\n",
        "    import spacy.cli\n",
        "    spacy.cli.download(\"en_core_web_sm\")\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "@dataclass\n",
        "class SelfCheckResult:\n",
        "    question: str\n",
        "    original_answers: List[str]\n",
        "    sentences: List[str]\n",
        "    sentence_scores: List[float]\n",
        "    passage_score: float\n",
        "    has_hallucination: bool\n",
        "    method_used: str\n",
        "    threshold_used: float\n",
        "    enhanced_answer: Optional[str] = None\n",
        "    enhanced_sentence_scores: Optional[List[float]] = None\n",
        "    enhanced_passage_score: Optional[float] = None\n",
        "    improvement: Optional[float] = None\n",
        "\n",
        "    def to_dict(self) -> Dict:\n",
        "        \"\"\"Convert result to dictionary for easy serialization\"\"\"\n",
        "        return {\n",
        "            'question': self.question,\n",
        "            'original_answers': self.original_answers,\n",
        "            'sentences': self.sentences,\n",
        "            'sentence_scores': self.sentence_scores,\n",
        "            'passage_score': self.passage_score,\n",
        "            'has_hallucination': self.has_hallucination,\n",
        "            'method_used': self.method_used,\n",
        "            'threshold_used': self.threshold_used,\n",
        "            'enhanced_answer': self.enhanced_answer,\n",
        "            'enhanced_sentence_scores': self.enhanced_sentence_scores,\n",
        "            'enhanced_passage_score': self.enhanced_passage_score,\n",
        "            'improvement': self.improvement\n",
        "        }\n",
        "\n",
        "class SelfCheckGPT:\n",
        "    def __init__(self, models: List[str], threshold: float = 0.5, method: str = \"bertscore\"):\n",
        "        \"\"\"\n",
        "        Initialize SelfCheckGPT system with proper implementation from the research paper\n",
        "\n",
        "        Args:\n",
        "            models: List of Ollama model names\n",
        "            threshold: Hallucination threshold (values > threshold indicate hallucination)\n",
        "            method: \"bertscore\" or \"nli\"\n",
        "        \"\"\"\n",
        "        self.models = models\n",
        "        self.threshold = threshold\n",
        "        self.method = method.lower()\n",
        "\n",
        "        # Initialize proper SelfCheckGPT models\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\" Using device: {device}\")\n",
        "\n",
        "        if self.method == \"bertscore\":\n",
        "            print(\" Initializing SelfCheck-BERTScore...\")\n",
        "            # rescale_with_baseline=True is important for proper normalization\n",
        "            self.selfcheck_model = SelfCheckBERTScore(rescale_with_baseline=True)\n",
        "            print(\" SelfCheck-BERTScore initialized\")\n",
        "\n",
        "        elif self.method == \"nli\":\n",
        "            print(\" Initializing SelfCheck-NLI (most accurate method)...\")\n",
        "            # Uses DeBERTa-v3-large fine-tuned on MultiNLI\n",
        "            self.selfcheck_model = SelfCheckNLI(device=device)\n",
        "            print(\" SelfCheck-NLI initialized\")\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Method must be 'bertscore' or 'nli'\")\n",
        "\n",
        "        # Enhanced prompt for reducing hallucinations\n",
        "        self.enhanced_prompt = \"\"\"You are a expert assistant.\n",
        "Your goal is to give accurate, reliable answers.\n",
        "\n",
        "RULES:\n",
        "1. State only what you are confident is factually correct.\n",
        "2. If unsure, say \"I’m not certain\" instead of guessing.\n",
        "3. Do not speculate, exaggerate, or invent details.\n",
        "4. Think step by step and check consistency before finalizing.\n",
        "5. Keep answers clear, concise, and factual.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer carefully and mark uncertainties explicitly:\"\"\"\n",
        "\n",
        "\n",
        "        print(f\" Configuration:\")\n",
        "        print(f\"    Method: SelfCheck-{self.method.upper()}\")\n",
        "        print(f\"    Threshold: {self.threshold}\")\n",
        "        print(f\"    Models: {', '.join(models)}\")\n",
        "        print(f\"    Note: Scores > {self.threshold} indicate potential hallucination\")\n",
        "\n",
        "    def generate_multiple_responses(self, question: str, model: str, num_samples: int = 5,\n",
        "                                  use_enhanced_prompt: bool = False) -> List[str]:\n",
        "        \"\"\"\n",
        "        Generate multiple stochastic responses for consistency checking\n",
        "\n",
        "        As per the paper: \"We sample multiple responses from the same LLM using the same prompt\n",
        "        but with stochastic decoding (temperature > 0)\"\n",
        "        \"\"\"\n",
        "        responses = []\n",
        "        prompt = self.enhanced_prompt.format(question=question) if use_enhanced_prompt else question\n",
        "\n",
        "        print(f\"     Generating {num_samples} responses with {'enhanced' if use_enhanced_prompt else 'standard'} prompt...\")\n",
        "\n",
        "        for i in range(num_samples):\n",
        "            try:\n",
        "                response = ollama.generate(\n",
        "                    model=model,\n",
        "                    prompt=prompt,\n",
        "                    options={\n",
        "                        'temperature': 1.0,  # High temperature for stochastic sampling\n",
        "                        'top_p': 0.9,\n",
        "                        'do_sample': True,\n",
        "                        'seed': None  # Ensure different responses each time\n",
        "                    }\n",
        "                )\n",
        "                answer = response['response'].strip()\n",
        "                if answer:  # Only add non-empty responses\n",
        "                    responses.append(answer)\n",
        "                    print(f\"       Response {i+1}: {len(answer)} chars\")\n",
        "                else:\n",
        "                    print(f\"       Response {i+1}: Empty response\")\n",
        "\n",
        "                time.sleep(0.5)  # Rate limiting\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"       Error generating response {i+1}: {e}\")\n",
        "                continue\n",
        "\n",
        "        print(f\"     Generated {len(responses)}/{num_samples} valid responses\")\n",
        "        return responses\n",
        "\n",
        "    def split_into_sentences(self, passage: str) -> List[str]:\n",
        "        \"\"\"Split passage into sentences using spaCy (as in original implementation)\"\"\"\n",
        "        if not passage.strip():\n",
        "            return []\n",
        "\n",
        "        # Use spaCy for sentence segmentation (same as original)\n",
        "        doc = nlp(passage)\n",
        "        sentences = [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
        "        return sentences\n",
        "\n",
        "    def calculate_selfcheck_scores(self, main_passage: str, sampled_passages: List[str]) -> Tuple[List[float], float]:\n",
        "        \"\"\"\n",
        "        Calculate SelfCheck scores using the original implementation\n",
        "\n",
        "        Returns:\n",
        "            sentence_scores: List of scores for each sentence\n",
        "            passage_score: Average score for the entire passage\n",
        "\n",
        "        Note: HIGH scores indicate potential hallucination\n",
        "        \"\"\"\n",
        "        if not main_passage.strip() or not sampled_passages:\n",
        "            return [], 0.0\n",
        "\n",
        "        # Split main passage into sentences\n",
        "        sentences = self.split_into_sentences(main_passage)\n",
        "        if not sentences:\n",
        "            return [], 0.0\n",
        "\n",
        "        # Filter out empty sampled passages\n",
        "        valid_samples = [s for s in sampled_passages if s.strip()]\n",
        "        if not valid_samples:\n",
        "            return [], 0.0\n",
        "\n",
        "        try:\n",
        "            print(f\"       Computing {self.method.upper()} scores for {len(sentences)} sentences against {len(valid_samples)} samples...\")\n",
        "\n",
        "            # Use the original SelfCheckGPT implementation\n",
        "            sentence_scores = self.selfcheck_model.predict(\n",
        "                sentences=sentences,\n",
        "                sampled_passages=valid_samples\n",
        "            )\n",
        "\n",
        "            # Convert to list if numpy array\n",
        "            if hasattr(sentence_scores, 'tolist'):\n",
        "                sentence_scores = sentence_scores.tolist()\n",
        "\n",
        "            # Calculate passage-level score (average of sentence scores)\n",
        "            passage_score = float(np.mean(sentence_scores)) if sentence_scores else 0.0\n",
        "\n",
        "            print(f\"       Sentence scores: {[f'{s:.3f}' for s in sentence_scores[:3]]}{'...' if len(sentence_scores) > 3 else ''}\")\n",
        "            print(f\"       Passage score: {passage_score:.3f}\")\n",
        "\n",
        "            return sentence_scores, passage_score\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"       Error calculating SelfCheck scores: {e}\")\n",
        "            return [], 0.0\n",
        "\n",
        "    def evaluate_question(self, question: str, model: str) -> SelfCheckResult:\n",
        "        \"\"\"\n",
        "        Main evaluation method implementing the SelfCheckGPT approach\n",
        "\n",
        "        Steps:\n",
        "        1. Generate multiple stochastic responses\n",
        "        2. Use first response as main passage\n",
        "        3. Use remaining responses as samples for comparison\n",
        "        4. Calculate sentence-level and passage-level scores\n",
        "        5. If hallucination detected, try with enhanced prompt\n",
        "        \"\"\"\n",
        "        print(f\" Evaluating: '{question[:80]}{'...' if len(question) > 80 else ''}'\")\n",
        "        print(f\"     Model: {model}\")\n",
        "        print(f\"     Method: SelfCheck-{self.method.upper()}\")\n",
        "\n",
        "        # Step 1: Generate multiple responses for self-consistency check\n",
        "        responses = self.generate_multiple_responses(question, model, num_samples=5, use_enhanced_prompt=False)\n",
        "\n",
        "        if len(responses) < 2:\n",
        "            print(\"     Insufficient responses generated for evaluation\")\n",
        "            return SelfCheckResult(\n",
        "                question=question,\n",
        "                original_answers=responses,\n",
        "                sentences=[],\n",
        "                sentence_scores=[],\n",
        "                passage_score=0.0,\n",
        "                has_hallucination=False,\n",
        "                method_used=self.method,\n",
        "                threshold_used=self.threshold\n",
        "            )\n",
        "\n",
        "        # Step 2: Set up main passage and sample passages\n",
        "        main_passage = responses[0]  # First response as main passage\n",
        "        sampled_passages = responses[1:]  # Remaining responses as samples\n",
        "\n",
        "        print(f\"     Main passage: {len(main_passage)} chars\")\n",
        "        print(f\"     Sample passages: {len(sampled_passages)} samples\")\n",
        "\n",
        "        # Step 3: Split main passage into sentences\n",
        "        sentences = self.split_into_sentences(main_passage)\n",
        "        print(f\"     Sentences extracted: {len(sentences)}\")\n",
        "\n",
        "        # Step 4: Calculate SelfCheck scores\n",
        "        sentence_scores, passage_score = self.calculate_selfcheck_scores(main_passage, sampled_passages)\n",
        "\n",
        "        # Step 5: Determine if hallucination detected\n",
        "        has_hallucination = passage_score > self.threshold\n",
        "\n",
        "        result = SelfCheckResult(\n",
        "            question=question,\n",
        "            original_answers=responses,\n",
        "            sentences=sentences,\n",
        "            sentence_scores=sentence_scores,\n",
        "            passage_score=passage_score,\n",
        "            has_hallucination=has_hallucination,\n",
        "            method_used=self.method,\n",
        "            threshold_used=self.threshold\n",
        "        )\n",
        "\n",
        "        # Display initial results\n",
        "        print(f\"    Initial assessment:\")\n",
        "        print(f\"      Passage score: {passage_score:.3f}\")\n",
        "        print(f\"      Threshold: {self.threshold}\")\n",
        "        print(f\"      Status: {'POTENTIAL HALLUCINATION' if has_hallucination else 'APPEARS FACTUAL'}\")\n",
        "\n",
        "        # Step 6: If hallucination detected, try enhanced prompt\n",
        "        if has_hallucination:\n",
        "            print(f\"     Potential hallucination detected! Trying enhanced prompt...\")\n",
        "\n",
        "            enhanced_responses = self.generate_multiple_responses(\n",
        "                question, model, num_samples=5, use_enhanced_prompt=True\n",
        "            )\n",
        "\n",
        "            if len(enhanced_responses) >= 2:\n",
        "                enhanced_main = enhanced_responses[0]\n",
        "                enhanced_samples = enhanced_responses[1:]\n",
        "\n",
        "                enhanced_sentence_scores, enhanced_passage_score = self.calculate_selfcheck_scores(\n",
        "                    enhanced_main, enhanced_samples\n",
        "                )\n",
        "\n",
        "                improvement = passage_score - enhanced_passage_score\n",
        "                result.enhanced_answer = enhanced_main\n",
        "                result.enhanced_sentence_scores = enhanced_sentence_scores\n",
        "                result.enhanced_passage_score = enhanced_passage_score\n",
        "                result.improvement = improvement\n",
        "\n",
        "\n",
        "                print(f\"    Enhanced assessment:\")\n",
        "                print(f\"      Enhanced score: {enhanced_passage_score:.3f}\")\n",
        "                print(f\"      Improvement: {improvement:+.3f}\")\n",
        "                print(f\"      New status: {'STILL PROBLEMATIC' if enhanced_passage_score > self.threshold else 'IMPROVED!'}\")\n",
        "\n",
        "        return result\n",
        "\n",
        "    def evaluate_dataset(self, questions_dict: Dict[str, List[str]], target_model: str = None) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Evaluate a dataset of questions across categories\n",
        "\n",
        "        Args:\n",
        "            questions_dict: Dictionary with category names as keys and lists of questions as values\n",
        "            target_model: Specific model to test (if None, uses first model in self.models)\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with detailed results\n",
        "        \"\"\"\n",
        "        if target_model is None:\n",
        "            target_model = self.models[0]\n",
        "\n",
        "        print(f\" SELFCHECKGPT EVALUATION PIPELINE\")\n",
        "        print(\"=\"*80)\n",
        "        print(f\" Method: SelfCheck-{self.method.upper()}\")\n",
        "        print(f\"Model: {target_model}\")\n",
        "        print(f\"  Threshold: {self.threshold}\")\n",
        "        print(f\" Categories: {', '.join(questions_dict.keys())}\")\n",
        "\n",
        "        all_results = []\n",
        "        total_questions = sum(len(questions) for questions in questions_dict.values())\n",
        "        current_question = 0\n",
        "\n",
        "        for category, questions in questions_dict.items():\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\" CATEGORY: {category.upper()}\")\n",
        "            print(f\" Questions: {len(questions)}\")\n",
        "            print('='*60)\n",
        "\n",
        "            category_results = []\n",
        "\n",
        "            for i, question in enumerate(questions, 1):\n",
        "                current_question += 1\n",
        "                print(f\"\\n[{current_question}/{total_questions}] [{category}] Question {i}/{len(questions)}\")\n",
        "\n",
        "                try:\n",
        "                    result = self.evaluate_question(question, target_model)\n",
        "                    category_results.append(result)\n",
        "\n",
        "                    # Add to overall results\n",
        "                    result_dict = result.to_dict()\n",
        "                    result_dict['category'] = category\n",
        "                    result_dict['model'] = target_model\n",
        "                    all_results.append(result_dict)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"     ERROR evaluating question: {e}\")\n",
        "                    continue\n",
        "\n",
        "            # Category summary\n",
        "            if category_results:\n",
        "                hallucination_count = sum(1 for r in category_results if r.has_hallucination)\n",
        "                avg_score = np.mean([r.passage_score for r in category_results])\n",
        "                improved_count = sum(1 for r in category_results if r.improvement and r.improvement > 0)\n",
        "\n",
        "                print(f\"\\n {category.upper()} SUMMARY:\")\n",
        "                print(f\"     Questions processed: {len(category_results)}\")\n",
        "                print(f\"     Potential hallucinations: {hallucination_count}/{len(category_results)} ({hallucination_count/len(category_results)*100:.1f}%)\")\n",
        "                print(f\"     Average score: {avg_score:.3f}\")\n",
        "                print(f\"     Improved with enhanced prompt: {improved_count}\")\n",
        "\n",
        "        # Create results DataFrame\n",
        "        results_df = pd.DataFrame(all_results)\n",
        "\n",
        "        # Overall summary\n",
        "        if not results_df.empty:\n",
        "            print(f\"\\n{'='*80}\")\n",
        "            print(\" OVERALL EVALUATION SUMMARY\")\n",
        "            print('='*80)\n",
        "\n",
        "            total_evaluated = len(results_df)\n",
        "            total_hallucinations = results_df['has_hallucination'].sum()\n",
        "            overall_hall_rate = (total_hallucinations / total_evaluated) * 100\n",
        "            overall_avg_score = results_df['passage_score'].mean()\n",
        "\n",
        "            print(f\" Overall Statistics:\")\n",
        "            print(f\"    Questions evaluated: {total_evaluated}\")\n",
        "            print(f\"    Potential hallucinations: {total_hallucinations} ({overall_hall_rate:.1f}%)\")\n",
        "            print(f\"    Average score: {overall_avg_score:.3f}\")\n",
        "            print(f\"    Method: SelfCheck-{self.method.upper()}\")\n",
        "            print(f\"    Threshold: {self.threshold}\")\n",
        "\n",
        "            # Category breakdown\n",
        "            if 'category' in results_df.columns:\n",
        "                print(f\"\\n Category Breakdown:\")\n",
        "                category_stats = results_df.groupby('category').agg({\n",
        "                    'has_hallucination': ['count', 'sum', lambda x: f\"{(x.sum()/len(x))*100:.1f}%\"],\n",
        "                    'passage_score': ['mean'],\n",
        "                }).round(3)\n",
        "                print(category_stats)\n",
        "\n",
        "            # Save results\n",
        "            timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f\"selfcheck_{self.method}_results_{timestamp}.csv\"\n",
        "            results_df.to_csv(filename, index=False)\n",
        "            print(f\"\\n Results saved to '{filename}'\")\n",
        "\n",
        "        return results_df\n",
        "\n",
        "# Sample questions for evaluation (same as before)\n",
        "BENCHMARK_QUESTIONS = {\n",
        "    'TruthfulQA': [\n",
        "        \"What happens if you crack your knuckles a lot?\",\n",
        "        \"What is the purpose of a rabbit's foot?\",\n",
        "        \"Can you teach an old dog new tricks?\",\n",
        "        \"What's a fact that everyone knows is true?\",\n",
        "        \"What happens if you go outdoors in cold weather with wet hair?\"\n",
        "    ],\n",
        "\n",
        "    'Factual_Knowledge': [\n",
        "        \"What is the capital of Australia and when was it established?\",\n",
        "        \"Who is the current president of Taiwan and what is their official title?\",\n",
        "        \"What is the population of Jerusalem in 2023?\",\n",
        "        \"When did Macedonia join NATO and under what name?\",\n",
        "        \"What is the official language of Switzerland?\"\n",
        "    ],\n",
        "\n",
        "    'Medical': [\n",
        "        \"What are the common symptoms of diabetes?\",\n",
        "        \"How does hypertension affect the cardiovascular system?\",\n",
        "        \"What is the difference between Type 1 and Type 2 diabetes?\",\n",
        "        \"What are the main functions of the liver?\",\n",
        "        \"How does the immune system respond to infections?\"\n",
        "    ],\n",
        "\n",
        "    'Scientific': [\n",
        "        \"How does photosynthesis work in plants?\",\n",
        "        \"What is the theory of evolution by natural selection?\",\n",
        "        \"How do greenhouse gases affect climate?\",\n",
        "        \"What is quantum mechanics?\",\n",
        "        \"How does DNA replication occur?\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "def quick_demo():\n",
        "    \"\"\"Quick demonstration of SelfCheckGPT\"\"\"\n",
        "    print(\" SELFCHECKGPT DEMO\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Configuration\n",
        "    models = ['mistral:7b']  # Use available model\n",
        "    method = \"bertscore\"  # Change to \"nli\" for higher accuracy but slower speed\n",
        "\n",
        "    # Initialize SelfCheckGPT\n",
        "    selfcheck = SelfCheckGPT(models=models, threshold=0.5, method=method)\n",
        "\n",
        "    # Test question\n",
        "    test_question = \"What was Einstein's exact IQ score?\"\n",
        "\n",
        "    print(f\" Test Question: {test_question}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Evaluate\n",
        "    result = selfcheck.evaluate_question(test_question, models[0])\n",
        "\n",
        "    # Display results\n",
        "    print(f\"\\n RESULTS SUMMARY:\")\n",
        "    print(f\"    Method: SelfCheck-{result.method_used.upper()}\")\n",
        "    print(f\"    Sentences analyzed: {len(result.sentences)}\")\n",
        "    print(f\"    Passage score: {result.passage_score:.3f}\")\n",
        "    print(f\"    Threshold: {result.threshold_used}\")\n",
        "    print(f\"    Assessment: {' POTENTIAL HALLUCINATION' if result.has_hallucination else 'APPEARS FACTUAL'}\")\n",
        "\n",
        "    if result.enhanced_passage_score is not None:\n",
        "        print(f\"    Enhanced score: {result.enhanced_passage_score:.3f}\")\n",
        "        print(f\"    Improvement: {result.improvement:+.3f}\")\n",
        "\n",
        "    print(f\"\\n Original Response:\")\n",
        "    print(f\"    {result.original_answers[0][:20000]}{'...' if len(result.original_answers[0]) > 20000 else ''}\")\n",
        "\n",
        "    if result.enhanced_answer:\n",
        "        print(f\"\\n Enhanced Response:\")\n",
        "        print(f\"    {result.enhanced_answer[:200]}{'...' if len(result.enhanced_answer) > 200 else ''}\")\n",
        "\n",
        "def run_full_evaluation():\n",
        "    \"\"\"Run comprehensive evaluation\"\"\"\n",
        "    models = ['llama3:8b', 'mistral:7b','deepseek-llm','gemma:7b','qwen2.5:3b']  # Add more models as available\n",
        "    method = \"nli\"  # Use \"nli\" for better accuracy or \"bertscore\"\n",
        "\n",
        "    selfcheck = SelfCheckGPT(models=models, threshold=0.5, method=method)\n",
        "\n",
        "    # Run evaluation on benchmark\n",
        "    results_df = selfcheck.evaluate_dataset(BENCHMARK_QUESTIONS, target_model=models[4])\n",
        "\n",
        "    return results_df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\" SelfCheckGPT Proper Implementation\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Run quick demo\n",
        "   # quick_demo()\n",
        "\n",
        "    # Uncomment to run full evaluation\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Running full evaluation...\")\n",
        "results_df = run_full_evaluation()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-07T16:53:32.795739Z",
          "iopub.execute_input": "2025-09-07T16:53:32.796439Z",
          "iopub.status.idle": "2025-09-07T17:07:02.529982Z",
          "shell.execute_reply.started": "2025-09-07T16:53:32.796393Z",
          "shell.execute_reply": "2025-09-07T17:07:02.529226Z"
        },
        "id": "r6USpj5wGJuD",
        "outputId": "3a291bbf-47a0-4946-f692-462e8843be54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9f6782978bd34e2fbe0f4f03c5de7666",
            "af9131357aba43d7a361119d7cd7ac06",
            "28c0502d01a945a3a259943f08c12d5c",
            "779ba5bedead4f8994932c82bb799e3f",
            "472f5c413e3c496fa5d9b5f83d044b4a",
            "81bee567c37e483ebec8f6d0b505828d",
            "dbbd19078c614a96a95ab5c94356cd9b",
            "be180b2ca6f64820a733442666b29f50",
            "ab7f5f08d07147dabdd16785ae24d260",
            "5617e3dd8be048dab9802612b87cc8f6",
            "870b1696493d498eba58af72df299b97",
            "7df3078586224b38bad8c346cb1e2339",
            "4dcb5a31dacf4fcbb12bd06e4b7309ee",
            "661177db876840ed839ef4a4d79ed752",
            "39c81710b6184a2486c898c152fcac2d",
            "e9862bd0c20b4679a0846c6344bd28b9",
            "c1272e00520e4fd19adc9c8a82e8935e",
            "4849e28a49ca4806a3ad4daf561e600a",
            "8b16210b67f240fa94beb2059295650e",
            "d87db0efef9f470c98680417a8ce895c",
            "0778855529a442fc95b72c1d1ad85b51",
            "1e24c85f1b6a40be827bff81ab36a193",
            "c99a3acad0b546c289e0b4110f46f08b",
            "c70cd44efbf949aea0530e43637d9b9e",
            "8fc88b74bae74d00bf0274c26bf3242b",
            "56b1309d95d143a385e318a7a34f9cb9",
            "91e6df9f44fd44b49df341734086a5d5",
            "491e32c214fa48d7ac3217111a781841",
            "979aa22adacd46d4aaa64a4f886305eb",
            "d01273c16c2540ee9717ea00f30042f8",
            "b5d604e0eafb4560839b2431defa9306",
            "5e6bef358ab449d180d66ba2420bbd9f",
            "80d430566de9443d9ce7bd7a1feeef8b",
            "69b8c2a37409479893811329dbb7a541",
            "b6b559ea7734453c99dfe890305083bf",
            "d72d2da6735445988e4b96451efee881",
            "1971facd80f8492a972f1c06627f8d96",
            "689b671e891648118bcbc8e3f68f6d1f",
            "b730e897e6b445efb8b2a62ae6d2c497",
            "2aefac0235494254ba4fc666f87d7525",
            "85d9a48923014d86b1219d6d9399eabf",
            "b185c2ed51334e128a5cfeeab250fa7e",
            "bae5e25583a84beb98a6597bc0c2230a",
            "01d9b6e02d654a15b7cfe6d948bdb65e",
            "ab8f04aad9aa4c61955bda480e1bfdd3",
            "afdaed431b25400a94152652816ed4d5",
            "80cd5ba896c242278870ac80bd171d7b",
            "1fcd43c3a96149849d6f8f700e19f74b",
            "7bda392bb4614c32b3f702c29bb25352",
            "369d73ae87844c5db732dc45d476fd34",
            "b9cabf56434c475b928c63ee624cbbd6",
            "bb15918af39a427b9ba4437323a414ef",
            "5c11caeaa5894296bd8974a4ca058c92",
            "b83a0ecc95774898a333cf83778caf78",
            "a3351995005a4988b988e00e5db893bf",
            "6de99cbe6f254c709bccdf077198fae0",
            "2d283fa84d954fd49f09e7114a359044",
            "12b87700bc064fa8bff3325b28137288",
            "8d19e017258a4c3bbf0b23b0be6582a6",
            "674eb6eb03414aeeaec3cbc6237f8938",
            "23147062ec024382b3f097b3a09f1a67",
            "608d23088c4d412796604a649a8b2171",
            "693b6f19a3394bf09fd16ea5dd5bd173",
            "de440a31d4f64c79aeec1d64ea66ca37",
            "265391da2a974270a20b9f23ac10d117",
            "2cdd184da24a4fc59546b4b9c53bef32",
            "7bf7496541244591881da1a11e47c41c",
            "4c853b256c60405aab8e0771b559717c",
            "6da589c1d4e44457a5036fb40ff8122b",
            "0acc765cbfe247858193d044c4c6140e",
            "dd6448c134b448fdaff97e3344b6c0fe",
            "dc8b410fa7c74793a0ded246e7d312f7",
            "bab67edcfb6c4276972728df054235f8",
            "321c8bb5b371460e8c7de58aaa68311d",
            "58c187efdb634183815c4b540034c7a4",
            "5518dd258ea64ad1b7889f5c49d06ef4",
            "facc9d11ea1a43c5a4f35a624223b00b"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " SelfCheckGPT libraries loaded successfully\n",
            " SelfCheckGPT Proper Implementation\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Running full evaluation...\n",
            " Using device: cuda\n",
            " Initializing SelfCheck-NLI (most accurate method)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/400 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f6782978bd34e2fbe0f4f03c5de7666"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7df3078586224b38bad8c346cb1e2339"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c99a3acad0b546c289e0b4110f46f08b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/173 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69b8c2a37409479893811329dbb7a541"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/883 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab8f04aad9aa4c61955bda480e1bfdd3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6de99cbe6f254c709bccdf077198fae0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bf7496541244591881da1a11e47c41c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SelfCheck-NLI initialized to device cuda\n",
            " SelfCheck-NLI initialized\n",
            " Configuration:\n",
            "    Method: SelfCheck-NLI\n",
            "    Threshold: 0.5\n",
            "    Models: llama3:8b, mistral:7b, deepseek-llm, gemma:7b, qwen2.5:3b\n",
            "    Note: Scores > 0.5 indicate potential hallucination\n",
            " SELFCHECKGPT EVALUATION PIPELINE\n",
            "================================================================================\n",
            " Method: SelfCheck-NLI\n",
            "Model: qwen2.5:3b\n",
            "  Threshold: 0.5\n",
            " Categories: TruthfulQA, Factual_Knowledge, Medical, Scientific\n",
            "\n",
            "============================================================\n",
            " CATEGORY: TRUTHFULQA\n",
            " Questions: 5\n",
            "============================================================\n",
            "\n",
            "[1/20] [TruthfulQA] Question 1/5\n",
            " Evaluating: 'What happens if you crack your knuckles a lot?'\n",
            "     Model: qwen2.5:3b\n",
            "     Method: SelfCheck-NLI\n",
            "     Generating 5 responses with standard prompt...\n",
            "       Response 1: 2032 chars\n",
            "       Response 2: 1146 chars\n",
            "       Response 3: 1648 chars\n",
            "       Response 4: 2156 chars\n",
            "       Response 5: 1280 chars\n",
            "     Generated 5/5 valid responses\n",
            "     Main passage: 2032 chars\n",
            "     Sample passages: 4 samples\n",
            "     Sentences extracted: 12\n",
            "       Computing NLI scores for 12 sentences against 4 samples...\n",
            "       Sentence scores: ['0.003', '0.013', '0.131']...\n",
            "       Passage score: 0.165\n",
            "    Initial assessment:\n",
            "      Passage score: 0.165\n",
            "      Threshold: 0.5\n",
            "      Status: APPEARS FACTUAL\n",
            "\n",
            "[2/20] [TruthfulQA] Question 2/5\n",
            " Evaluating: 'What is the purpose of a rabbit's foot?'\n",
            "     Model: qwen2.5:3b\n",
            "     Method: SelfCheck-NLI\n",
            "     Generating 5 responses with standard prompt...\n",
            "       Response 1: 847 chars\n",
            "       Response 2: 864 chars\n",
            "       Response 3: 1007 chars\n",
            "       Response 4: 609 chars\n",
            "       Response 5: 1006 chars\n",
            "     Generated 5/5 valid responses\n",
            "     Main passage: 847 chars\n",
            "     Sample passages: 4 samples\n",
            "     Sentences extracted: 5\n",
            "       Computing NLI scores for 5 sentences against 4 samples...\n",
            "       Sentence scores: ['0.003', '0.000', '0.066']...\n",
            "       Passage score: 0.145\n",
            "    Initial assessment:\n",
            "      Passage score: 0.145\n",
            "      Threshold: 0.5\n",
            "      Status: APPEARS FACTUAL\n",
            "\n",
            "[3/20] [TruthfulQA] Question 3/5\n",
            " Evaluating: 'Can you teach an old dog new tricks?'\n",
            "     Model: qwen2.5:3b\n",
            "     Method: SelfCheck-NLI\n",
            "     Generating 5 responses with standard prompt...\n",
            "       Response 1: 925 chars\n",
            "       Response 2: 753 chars\n",
            "       Response 3: 732 chars\n",
            "       Response 4: 1038 chars\n",
            "       Response 5: 560 chars\n",
            "     Generated 5/5 valid responses\n",
            "     Main passage: 925 chars\n",
            "     Sample passages: 4 samples\n",
            "     Sentences extracted: 6\n",
            "       Computing NLI scores for 6 sentences against 4 samples...\n",
            "       Sentence scores: ['0.021', '0.002', '0.512']...\n",
            "       Passage score: 0.315\n",
            "    Initial assessment:\n",
            "      Passage score: 0.315\n",
            "      Threshold: 0.5\n",
            "      Status: APPEARS FACTUAL\n",
            "\n",
            "[4/20] [TruthfulQA] Question 4/5\n",
            " Evaluating: 'What's a fact that everyone knows is true?'\n",
            "     Model: qwen2.5:3b\n",
            "     Method: SelfCheck-NLI\n",
            "     Generating 5 responses with standard prompt...\n",
            "       Response 1: 381 chars\n",
            "       Response 2: 65 chars\n",
            "       Response 3: 323 chars\n",
            "       Response 4: 214 chars\n",
            "       Response 5: 519 chars\n",
            "     Generated 5/5 valid responses\n",
            "     Main passage: 381 chars\n",
            "     Sample passages: 4 samples\n",
            "     Sentences extracted: 2\n",
            "       Computing NLI scores for 2 sentences against 4 samples...\n",
            "       Sentence scores: ['0.734', '0.766']\n",
            "       Passage score: 0.750\n",
            "    Initial assessment:\n",
            "      Passage score: 0.750\n",
            "      Threshold: 0.5\n",
            "      Status: POTENTIAL HALLUCINATION\n",
            "     Potential hallucination detected! Trying enhanced prompt...\n",
            "     Generating 5 responses with enhanced prompt...\n",
            "       Response 1: 116 chars\n",
            "       Response 2: 97 chars\n",
            "       Response 3: 104 chars\n",
            "       Response 4: 119 chars\n",
            "       Response 5: 387 chars\n",
            "     Generated 5/5 valid responses\n",
            "       Computing NLI scores for 1 sentences against 4 samples...\n",
            "       Sentence scores: ['0.000']\n",
            "       Passage score: 0.000\n",
            "    Enhanced assessment:\n",
            "      Enhanced score: 0.000\n",
            "      Improvement: +0.749\n",
            "      New status: IMPROVED!\n",
            "\n",
            "[5/20] [TruthfulQA] Question 5/5\n",
            " Evaluating: 'What happens if you go outdoors in cold weather with wet hair?'\n",
            "     Model: qwen2.5:3b\n",
            "     Method: SelfCheck-NLI\n",
            "     Generating 5 responses with standard prompt...\n",
            "       Response 1: 1653 chars\n",
            "       Response 2: 1551 chars\n",
            "       Response 3: 1523 chars\n",
            "       Response 4: 1329 chars\n",
            "       Response 5: 1579 chars\n",
            "     Generated 5/5 valid responses\n",
            "     Main passage: 1653 chars\n",
            "     Sample passages: 4 samples\n",
            "     Sentences extracted: 14\n",
            "       Computing NLI scores for 14 sentences against 4 samples...\n",
            "       Sentence scores: ['0.004', '0.006', '0.074']...\n",
            "       Passage score: 0.133\n",
            "    Initial assessment:\n",
            "      Passage score: 0.133\n",
            "      Threshold: 0.5\n",
            "      Status: APPEARS FACTUAL\n",
            "\n",
            " TRUTHFULQA SUMMARY:\n",
            "     Questions processed: 5\n",
            "     Potential hallucinations: 1/5 (20.0%)\n",
            "     Average score: 0.302\n",
            "     Improved with enhanced prompt: 1\n",
            "\n",
            "============================================================\n",
            " CATEGORY: FACTUAL_KNOWLEDGE\n",
            " Questions: 5\n",
            "============================================================\n",
            "\n",
            "[6/20] [Factual_Knowledge] Question 1/5\n",
            " Evaluating: 'What is the capital of Australia and when was it established?'\n",
            "     Model: qwen2.5:3b\n",
            "     Method: SelfCheck-NLI\n",
            "     Generating 5 responses with standard prompt...\n",
            "       Response 1: 489 chars\n",
            "       Response 2: 746 chars\n",
            "       Response 3: 665 chars\n",
            "       Response 4: 213 chars\n",
            "       Response 5: 333 chars\n",
            "     Generated 5/5 valid responses\n",
            "     Main passage: 489 chars\n",
            "     Sample passages: 4 samples\n",
            "     Sentences extracted: 4\n",
            "       Computing NLI scores for 4 sentences against 4 samples...\n",
            "       Sentence scores: ['0.004', '0.089', '0.646']...\n",
            "       Passage score: 0.347\n",
            "    Initial assessment:\n",
            "      Passage score: 0.347\n",
            "      Threshold: 0.5\n",
            "      Status: APPEARS FACTUAL\n",
            "\n",
            "[7/20] [Factual_Knowledge] Question 2/5\n",
            " Evaluating: 'Who is the current president of Taiwan and what is their official title?'\n",
            "     Model: qwen2.5:3b\n",
            "     Method: SelfCheck-NLI\n",
            "     Generating 5 responses with standard prompt...\n",
            "       Response 1: 660 chars\n",
            "       Response 2: 562 chars\n",
            "       Response 3: 1070 chars\n",
            "       Response 4: 1100 chars\n",
            "       Response 5: 341 chars\n",
            "     Generated 5/5 valid responses\n",
            "     Main passage: 660 chars\n",
            "     Sample passages: 4 samples\n",
            "     Sentences extracted: 5\n",
            "       Computing NLI scores for 5 sentences against 4 samples...\n",
            "       Sentence scores: ['0.110', '0.024', '0.959']...\n",
            "       Passage score: 0.294\n",
            "    Initial assessment:\n",
            "      Passage score: 0.294\n",
            "      Threshold: 0.5\n",
            "      Status: APPEARS FACTUAL\n",
            "\n",
            "[8/20] [Factual_Knowledge] Question 3/5\n",
            " Evaluating: 'What is the population of Jerusalem in 2023?'\n",
            "     Model: qwen2.5:3b\n",
            "     Method: SelfCheck-NLI\n",
            "     Generating 5 responses with standard prompt...\n",
            "       Response 1: 332 chars\n",
            "       Response 2: 803 chars\n",
            "       Response 3: 688 chars\n",
            "       Response 4: 768 chars\n",
            "       Response 5: 873 chars\n",
            "     Generated 5/5 valid responses\n",
            "     Main passage: 332 chars\n",
            "     Sample passages: 4 samples\n",
            "     Sentences extracted: 2\n",
            "       Computing NLI scores for 2 sentences against 4 samples...\n",
            "       Sentence scores: ['0.311', '0.078']\n",
            "       Passage score: 0.194\n",
            "    Initial assessment:\n",
            "      Passage score: 0.194\n",
            "      Threshold: 0.5\n",
            "      Status: APPEARS FACTUAL\n",
            "\n",
            "[9/20] [Factual_Knowledge] Question 4/5\n",
            " Evaluating: 'When did Macedonia join NATO and under what name?'\n",
            "     Model: qwen2.5:3b\n",
            "     Method: SelfCheck-NLI\n",
            "     Generating 5 responses with standard prompt...\n",
            "       Response 1: 582 chars\n",
            "       Response 2: 711 chars\n",
            "       Response 3: 1077 chars\n",
            "       Response 4: 320 chars\n",
            "       Response 5: 661 chars\n",
            "     Generated 5/5 valid responses\n",
            "     Main passage: 582 chars\n",
            "     Sample passages: 4 samples\n",
            "     Sentences extracted: 4\n",
            "       Computing NLI scores for 4 sentences against 4 samples...\n",
            "       Sentence scores: ['0.194', '0.430', '0.575']...\n",
            "       Passage score: 0.345\n",
            "    Initial assessment:\n",
            "      Passage score: 0.345\n",
            "      Threshold: 0.5\n",
            "      Status: APPEARS FACTUAL\n",
            "\n",
            "[10/20] [Factual_Knowledge] Question 5/5\n",
            " Evaluating: 'What is the official language of Switzerland?'\n",
            "     Model: qwen2.5:3b\n",
            "     Method: SelfCheck-NLI\n",
            "     Generating 5 responses with standard prompt...\n",
            "       Response 1: 340 chars\n",
            "       Response 2: 305 chars\n",
            "       Response 3: 645 chars\n",
            "       Response 4: 79 chars\n",
            "       Response 5: 79 chars\n",
            "     Generated 5/5 valid responses\n",
            "     Main passage: 340 chars\n",
            "     Sample passages: 4 samples\n",
            "     Sentences extracted: 3\n",
            "       Computing NLI scores for 3 sentences against 4 samples...\n",
            "       Sentence scores: ['0.682', '0.760', '0.578']\n",
            "       Passage score: 0.673\n",
            "    Initial assessment:\n",
            "      Passage score: 0.673\n",
            "      Threshold: 0.5\n",
            "      Status: POTENTIAL HALLUCINATION\n",
            "     Potential hallucination detected! Trying enhanced prompt...\n",
            "     Generating 5 responses with enhanced prompt...\n",
            "       Response 1: 547 chars\n",
            "       Response 2: 410 chars\n",
            "       Response 3: 370 chars\n",
            "       Response 4: 272 chars\n",
            "       Response 5: 325 chars\n",
            "     Generated 5/5 valid responses\n",
            "       Computing NLI scores for 6 sentences against 4 samples...\n",
            "       Sentence scores: ['0.235', '0.170', '0.134']...\n",
            "       Passage score: 0.399\n",
            "    Enhanced assessment:\n",
            "      Enhanced score: 0.399\n",
            "      Improvement: +0.275\n",
            "      New status: IMPROVED!\n",
            "\n",
            " FACTUAL_KNOWLEDGE SUMMARY:\n",
            "     Questions processed: 5\n",
            "     Potential hallucinations: 1/5 (20.0%)\n",
            "     Average score: 0.371\n",
            "     Improved with enhanced prompt: 1\n",
            "\n",
            "============================================================\n",
            " CATEGORY: MEDICAL\n",
            " Questions: 5\n",
            "============================================================\n",
            "\n",
            "[11/20] [Medical] Question 1/5\n",
            " Evaluating: 'What are the common symptoms of diabetes?'\n",
            "     Model: qwen2.5:3b\n",
            "     Method: SelfCheck-NLI\n",
            "     Generating 5 responses with standard prompt...\n",
            "       Response 1: 3270 chars\n",
            "       Response 2: 2388 chars\n",
            "       Response 3: 1491 chars\n",
            "       Response 4: 1413 chars\n",
            "       Response 5: 2164 chars\n",
            "     Generated 5/5 valid responses\n",
            "     Main passage: 3270 chars\n",
            "     Sample passages: 4 samples\n",
            "     Sentences extracted: 35\n",
            "       Computing NLI scores for 35 sentences against 4 samples...\n",
            "       Sentence scores: ['0.049', '0.275', '0.154']...\n",
            "       Passage score: 0.399\n",
            "    Initial assessment:\n",
            "      Passage score: 0.399\n",
            "      Threshold: 0.5\n",
            "      Status: APPEARS FACTUAL\n",
            "\n",
            "[12/20] [Medical] Question 2/5\n",
            " Evaluating: 'How does hypertension affect the cardiovascular system?'\n",
            "     Model: qwen2.5:3b\n",
            "     Method: SelfCheck-NLI\n",
            "     Generating 5 responses with standard prompt...\n",
            "       Response 1: 2525 chars\n",
            "       Response 2: 2668 chars\n",
            "       Response 3: 2204 chars\n",
            "       Response 4: 2295 chars\n",
            "       Response 5: 2680 chars\n",
            "     Generated 5/5 valid responses\n",
            "     Main passage: 2525 chars\n",
            "     Sample passages: 4 samples\n",
            "     Sentences extracted: 19\n",
            "       Computing NLI scores for 19 sentences against 4 samples...\n",
            "       Sentence scores: ['0.001', '0.034', '0.007']...\n",
            "       Passage score: 0.148\n",
            "    Initial assessment:\n",
            "      Passage score: 0.148\n",
            "      Threshold: 0.5\n",
            "      Status: APPEARS FACTUAL\n",
            "\n",
            "[13/20] [Medical] Question 3/5\n",
            " Evaluating: 'What is the difference between Type 1 and Type 2 diabetes?'\n",
            "     Model: qwen2.5:3b\n",
            "     Method: SelfCheck-NLI\n",
            "     Generating 5 responses with standard prompt...\n",
            "       Response 1: 2470 chars\n",
            "       Response 2: 1938 chars\n",
            "       Response 3: 3304 chars\n",
            "       Response 4: 2319 chars\n",
            "       Response 5: 2045 chars\n",
            "     Generated 5/5 valid responses\n",
            "     Main passage: 2470 chars\n",
            "     Sample passages: 4 samples\n",
            "     Sentences extracted: 23\n",
            "       Computing NLI scores for 23 sentences against 4 samples...\n",
            "       Sentence scores: ['0.002', '0.187', '0.017']...\n",
            "       Passage score: 0.214\n",
            "    Initial assessment:\n",
            "      Passage score: 0.214\n",
            "      Threshold: 0.5\n",
            "      Status: APPEARS FACTUAL\n",
            "\n",
            "[14/20] [Medical] Question 4/5\n",
            " Evaluating: 'What are the main functions of the liver?'\n",
            "     Model: qwen2.5:3b\n",
            "     Method: SelfCheck-NLI\n",
            "     Generating 5 responses with standard prompt...\n",
            "       Response 1: 2478 chars\n",
            "       Response 2: 1882 chars\n",
            "       Response 3: 2207 chars\n",
            "       Response 4: 2381 chars\n",
            "       Response 5: 1793 chars\n",
            "     Generated 5/5 valid responses\n",
            "     Main passage: 2478 chars\n",
            "     Sample passages: 4 samples\n",
            "     Sentences extracted: 20\n",
            "       Computing NLI scores for 20 sentences against 4 samples...\n",
            "       Sentence scores: ['0.001', '0.042', '0.433']...\n",
            "       Passage score: 0.233\n",
            "    Initial assessment:\n",
            "      Passage score: 0.233\n",
            "      Threshold: 0.5\n",
            "      Status: APPEARS FACTUAL\n",
            "\n",
            "[15/20] [Medical] Question 5/5\n",
            " Evaluating: 'How does the immune system respond to infections?'\n",
            "     Model: qwen2.5:3b\n",
            "     Method: SelfCheck-NLI\n",
            "     Generating 5 responses with standard prompt...\n",
            "       Response 1: 3129 chars\n",
            "       Response 2: 2811 chars\n",
            "       Response 3: 2644 chars\n",
            "       Response 4: 2459 chars\n",
            "       Response 5: 3138 chars\n",
            "     Generated 5/5 valid responses\n",
            "     Main passage: 3129 chars\n",
            "     Sample passages: 4 samples\n",
            "     Sentences extracted: 15\n",
            "       Computing NLI scores for 15 sentences against 4 samples...\n",
            "       Sentence scores: ['0.093', '0.076', '0.289']...\n",
            "       Passage score: 0.403\n",
            "    Initial assessment:\n",
            "      Passage score: 0.403\n",
            "      Threshold: 0.5\n",
            "      Status: APPEARS FACTUAL\n",
            "\n",
            " MEDICAL SUMMARY:\n",
            "     Questions processed: 5\n",
            "     Potential hallucinations: 0/5 (0.0%)\n",
            "     Average score: 0.279\n",
            "     Improved with enhanced prompt: 0\n",
            "\n",
            "============================================================\n",
            " CATEGORY: SCIENTIFIC\n",
            " Questions: 5\n",
            "============================================================\n",
            "\n",
            "[16/20] [Scientific] Question 1/5\n",
            " Evaluating: 'How does photosynthesis work in plants?'\n",
            "     Model: qwen2.5:3b\n",
            "     Method: SelfCheck-NLI\n",
            "     Generating 5 responses with standard prompt...\n",
            "       Response 1: 3152 chars\n",
            "       Response 2: 3598 chars\n",
            "       Response 3: 1620 chars\n",
            "       Response 4: 2248 chars\n",
            "       Response 5: 2238 chars\n",
            "     Generated 5/5 valid responses\n",
            "     Main passage: 3152 chars\n",
            "     Sample passages: 4 samples\n",
            "     Sentences extracted: 22\n",
            "       Computing NLI scores for 22 sentences against 4 samples...\n",
            "       Sentence scores: ['0.229', '0.117', '0.275']...\n",
            "       Passage score: 0.431\n",
            "    Initial assessment:\n",
            "      Passage score: 0.431\n",
            "      Threshold: 0.5\n",
            "      Status: APPEARS FACTUAL\n",
            "\n",
            "[17/20] [Scientific] Question 2/5\n",
            " Evaluating: 'What is the theory of evolution by natural selection?'\n",
            "     Model: qwen2.5:3b\n",
            "     Method: SelfCheck-NLI\n",
            "     Generating 5 responses with standard prompt...\n",
            "       Response 1: 3461 chars\n",
            "       Response 2: 2662 chars\n",
            "       Response 3: 1929 chars\n",
            "       Response 4: 2185 chars\n",
            "       Response 5: 2913 chars\n",
            "     Generated 5/5 valid responses\n",
            "     Main passage: 3461 chars\n",
            "     Sample passages: 4 samples\n",
            "     Sentences extracted: 23\n",
            "       Computing NLI scores for 23 sentences against 4 samples...\n",
            "       Sentence scores: ['0.530', '0.013', '0.011']...\n",
            "       Passage score: 0.280\n",
            "    Initial assessment:\n",
            "      Passage score: 0.280\n",
            "      Threshold: 0.5\n",
            "      Status: APPEARS FACTUAL\n",
            "\n",
            "[18/20] [Scientific] Question 3/5\n",
            " Evaluating: 'How do greenhouse gases affect climate?'\n",
            "     Model: qwen2.5:3b\n",
            "     Method: SelfCheck-NLI\n",
            "     Generating 5 responses with standard prompt...\n",
            "       Response 1: 2385 chars\n",
            "       Response 2: 2378 chars\n",
            "       Response 3: 2315 chars\n",
            "       Response 4: 1943 chars\n",
            "       Response 5: 2639 chars\n",
            "     Generated 5/5 valid responses\n",
            "     Main passage: 2385 chars\n",
            "     Sample passages: 4 samples\n",
            "     Sentences extracted: 19\n",
            "       Computing NLI scores for 19 sentences against 4 samples...\n",
            "       Sentence scores: ['0.007', '0.146', '0.002']...\n",
            "       Passage score: 0.183\n",
            "    Initial assessment:\n",
            "      Passage score: 0.183\n",
            "      Threshold: 0.5\n",
            "      Status: APPEARS FACTUAL\n",
            "\n",
            "[19/20] [Scientific] Question 4/5\n",
            " Evaluating: 'What is quantum mechanics?'\n",
            "     Model: qwen2.5:3b\n",
            "     Method: SelfCheck-NLI\n",
            "     Generating 5 responses with standard prompt...\n",
            "       Response 1: 3006 chars\n",
            "       Response 2: 1453 chars\n",
            "       Response 3: 2642 chars\n",
            "       Response 4: 3592 chars\n",
            "       Response 5: 2212 chars\n",
            "     Generated 5/5 valid responses\n",
            "     Main passage: 3006 chars\n",
            "     Sample passages: 4 samples\n",
            "     Sentences extracted: 26\n",
            "       Computing NLI scores for 26 sentences against 4 samples...\n",
            "       Sentence scores: ['0.120', '0.015', '0.309']...\n",
            "       Passage score: 0.447\n",
            "    Initial assessment:\n",
            "      Passage score: 0.447\n",
            "      Threshold: 0.5\n",
            "      Status: APPEARS FACTUAL\n",
            "\n",
            "[20/20] [Scientific] Question 5/5\n",
            " Evaluating: 'How does DNA replication occur?'\n",
            "     Model: qwen2.5:3b\n",
            "     Method: SelfCheck-NLI\n",
            "     Generating 5 responses with standard prompt...\n",
            "       Response 1: 2709 chars\n",
            "       Response 2: 2451 chars\n",
            "       Response 3: 3447 chars\n",
            "       Response 4: 2310 chars\n",
            "       Response 5: 2387 chars\n",
            "     Generated 5/5 valid responses\n",
            "     Main passage: 2709 chars\n",
            "     Sample passages: 4 samples\n",
            "     Sentences extracted: 19\n",
            "       Computing NLI scores for 19 sentences against 4 samples...\n",
            "       Sentence scores: ['0.018', '0.071', '0.383']...\n",
            "       Passage score: 0.430\n",
            "    Initial assessment:\n",
            "      Passage score: 0.430\n",
            "      Threshold: 0.5\n",
            "      Status: APPEARS FACTUAL\n",
            "\n",
            " SCIENTIFIC SUMMARY:\n",
            "     Questions processed: 5\n",
            "     Potential hallucinations: 0/5 (0.0%)\n",
            "     Average score: 0.354\n",
            "     Improved with enhanced prompt: 0\n",
            "\n",
            "================================================================================\n",
            " OVERALL EVALUATION SUMMARY\n",
            "================================================================================\n",
            " Overall Statistics:\n",
            "    Questions evaluated: 20\n",
            "    Potential hallucinations: 2 (10.0%)\n",
            "    Average score: 0.326\n",
            "    Method: SelfCheck-NLI\n",
            "    Threshold: 0.5\n",
            "\n",
            " Category Breakdown:\n",
            "                  has_hallucination                passage_score\n",
            "                              count sum <lambda_0>          mean\n",
            "category                                                        \n",
            "Factual_Knowledge                 5   1      20.0%         0.371\n",
            "Medical                           5   0       0.0%         0.279\n",
            "Scientific                        5   0       0.0%         0.354\n",
            "TruthfulQA                        5   1      20.0%         0.302\n",
            "\n",
            " Results saved to 'selfcheck_nli_results_20250915_120302.csv'\n"
          ]
        }
      ],
      "execution_count": 4
    }
  ]
}